# 零、解题思路

[1]面对一个未知问题时，你可以从复杂度入手。尝试去分析这个问题的时间复杂度上限是多少，也就是复杂度再高能高到哪里。这就是不计任何时间、空间损耗，采用暴力求解的方法去解题。然后分析这个问题的时间复杂度下限是多少，也就是时间复杂度再低能低到哪里。这就是你写代码的目标。

[2]接着，尝试去定位问题。在分析出这两个问题之后，就需要去设计合理的数据结构和运用合适的算法思维，**从暴力求解的方法去逼近写代码的目标了。**
在这里需要先定位问题，这个问题的类型就决定了采用哪种算法思维。

[3]最后，需要对数据操作进行分析。例如：在这个问题中，**需要对数据进行哪些操作（增删查）**，数据之间是否需要保证顺序或逆序？当分析出这些操作的步骤、频次之后，就可以根据不同数据结构的特性，去合理选择你所应该使用的那几种数据结构了。

经过以上分析，我们对方法论进行提练，宏观上的步骤总结为以下 4 步：

[1]复杂度分析。估算问题中复杂度的上限和下限。

[2]定位问题。根据问题类型，确定采用何种算法思维。

[3]数据操作分析。**根据增、删、查和数据顺序关系去选择合适的数据结构，利用空间换取时间**。

[4]编码实现。

这套方法适用于绝大多数的问题，在实战中需要你灵活运用。

# 一、数据结构与算法

## 1、线性结构和非线性结构

（1）线性：数组和链表，包括数组、队列、栈、链表

（2）非线性：二维数据，多维数组，广义表，图，树

![913e0ababe43a2d57267df5c5f0832a7](img\913e0ababe43a2d57267df5c5f0832a7.jpg)

## 2、时间复杂度和空间复杂度

常见的空间复杂度就是 O(1)、O(n)、O(n2 )，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。

空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间

![3723793cc5c810e9d5b06bc95325bf0a](img\3723793cc5c810e9d5b06bc95325bf0a.jpg)

### 

【1】时间频度：一个算法中的语句执行次数称为语句频度或时间频度。记为T(n)

【2】时间复杂度：T(n)=Ｏ( f(n) )

Ο(1)＜Ο(log2n)＜Ο(n)＜Ο(nlog2n)＜Ο(n2)＜Ο(n3)＜ Ο(nk) ＜Ο(2n) <O(n!)



O(log2n)

![图片1](img\图片1.png)



在while循环里面，每次都将 i 乘以 2，乘完之后，i 距离 n 就越来越近了。假设循环x次之后，i 就大于 2 了，此时这个循环就退出了，也就是说 2 的 x 次方等于 n，那么 x = log2n也就是说当循环 log2n 次以后，这个代码就结束了。因此这个代码的时间复杂度为：O(log2n)  。 O(log2n) 的这个2 时间上是根据代码变化的，i = i * 3 ，则是 O(log3n) 

【3】空间复杂度：缓存产品(redis, memcache)和算法(基数排序)本质就是用空间换时间.

# 二、线性

## 1、数组

### （1）概念

数组支持随机访问，根据<font color=red>**下标随机访问**</font>的时间复杂度为 O(1)，

不能表述为“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”，数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。

数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读

### （2）插入、删除

#### 【1】插入

如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置

![3f70b4ad9069ec568a2caaddc231b7dc](img\3f70b4ad9069ec568a2caaddc231b7dc.jpg)

在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在<font color=red>**快排**</font>中也会用到，我会在排序那一节具体来讲，这里就说到这儿。

#### 【2】删除

数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

<font color=red>**JVM 标记清除垃圾回收算法**</font>



![b69b8c5dbf6248649ddab7d3e7cfd7e5](img\b69b8c5dbf6248649ddab7d3e7cfd7e5.jpg)

### （3）稀疏数组

【1】实际问题：棋盘、地图等

<img src="img\QQ截图20200516180620.png" alt="QQ截图20200516180620" style="zoom:80%;" />

【2】解决

稀疏数组的处理方法是:
[1]记录数组一共有几行几列，有多少个不同的值
[2]把具有不同值的元素的行列及值记录在一个小规模的数组中，从而缩小程序的规模

[3]二维数组 转 稀疏数组的思路

```
1. 遍历  原始的二维数组，得到有效数据的个数 sum
2. 根据sum 就可以创建 稀疏数组 sparseArr   int[sum + 1][3]
3. 将二维数组的有效数据数据存入到 稀疏数组
```



[4]稀疏数组转原始的二维数组的思路

```
1.先读取稀疏数组的第一行，根据第一行的数据，创建原始的二维数组，比如上面的  chessArr2 = int [11][11]

2.在读取稀疏数组后几行的数据，并赋给 原始的二维数组 即可.
```

<img src="img\QQ截图20200516180823.png" alt="QQ截图20200516180823" style="zoom:80%;" />

## 2、队列（queue）

数组、链表都可以实现

![Ciqc1F7XiWKAYQ6uAABDmk0Wx98597](img\Ciqc1F7XiWKAYQ6uAABDmk0Wx98597.png)

### （1） 顺序队列（数组）

因为队列的输出、输入是分别从前后端来处理，因此需要两个变量 front及 rear分别记录队列前后端的下标，front 会随着数据输出而改变，而 rear则是随着数据输入而改变

【1】构造器

front=-1，指向队列头部，是队列第一个数据的前一个位置

rear=-1，指向队列尾部，是最后一个数据的位置

【2】队满

rear  == maxSize - 1

【3】队空

front==rear

【4】入队

将尾指针往后移：rear++

【5】出队（获取数据）

front++

【6】peek

arr[front+1]

### （2）环形队列（数组）

1. front 变量的含义做一个调整： front 就指向队列的第一个元素, 也就是说 arr[front] 就是队列的第一个元素， 
   front 的初始值 = 0

2. rear 变量的含义做一个调整：rear 指向队列的最后一个元素的后一个位置. 因为希望空出一个空间做为约定，
   rear 的初始值 = 0

3. 当队列满时，条件是  (rear  + 1) % maxSize == front 【满】

   tail=3，head=4，n=8，所以总结一下规律就是：(3+1)%8=4。多画几张队满的图，你就会发现，当队满时，(tail+1)%n=head。你有没有发现，当队列满时，图中的 tail 指向的位置实际上是没有存储数据的。所以，**循环队列会浪费一个数组的存储空间**

4.  对队列为空的条件， rear == front 空

5. 当我们这样分析， 队列中有效的数据的个数   (rear + maxSize - front) % maxSize   // rear = 1 front = 0 

6. 我们就可以在原来的队列上修改得到，一个环形队列

【1】入队

rear=(rear+1)%maxSize

【2】出队

```java
// 1. 先把 front 对应的值保留到一个临时变量
// 2. 将 front 后移, 考虑取模
// 3. 将临时保存的变量返回
int value = arr[front];
front = (front + 1) % maxSize;
```

【3】peek

arr[front]

【4】遍历

```java
for (int i = front; i < front + size() ; i++) {
			System.out.printf("arr[%d]=%d\n", i % maxSize, arr[i % maxSize]);
}
```

<img src="img\3d81a44f8c42b3ceee55605f9aeedcec.jpg" alt="3d81a44f8c42b3ceee55605f9aeedcec" style="zoom:60%;" />



### （3）应用场景

#### 【1】阻塞队列

在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

可以使用阻塞队列，轻松实现一个**“生产者 - 消费者模型”**

![5ef3326181907dea0964f612890185eb](img\5ef3326181907dea0964f612890185eb.jpg)

#### 【2】并发队列

线程安全的队列我们叫作并发队列。基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因

【3】高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等；**数据库连接池的排队请求**

## 3、链表

### （1）LRU

缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）

## 4、单链表（Linked List）

### （1）物理结构

![QQ截图20200516215648](img\QQ截图20200516215648.png)



### （2）增删改查

#### 【1】顺序插入（尾插）

```java
	private HeroNode head = new HeroNode(0, "", "");
	
	
	//返回头节点
	public HeroNode getHead() {
		return head;
	}

	//添加节点到单向链表
	//思路，当不考虑编号顺序时
	//1. 找到当前链表的最后节点
	//2. 将最后这个节点的next 指向 新的节点
	public void add(HeroNode heroNode) {
		
		//因为head节点不能动，因此我们需要一个辅助遍历 temp
		HeroNode temp = head;
		//遍历链表，找到最后
		while(temp.next!=null) {
			
			//如果没有找到最后, 将将temp后移
			temp = temp.next;
		}
		//当退出while循环时，temp就指向了链表的最后
		//将最后这个节点的next 指向 新的节点
		temp.next = heroNode;
	}
```

#### 【2】先查询后插入，查找到合适的之后再插入

1. 首先找到新添加的节点的位置, 是通过辅助变量(指针), 通过遍历来搞定
2. 新的节点.next = temp.next

3. 将temp.next = 新的节点

```java
public void addByOrder(HeroNode heroNode) {
		//因为头节点不能动，因此我们仍然通过一个辅助指针(变量)来帮助找到添加的位置
		//因为单链表，因为我们找的temp 是位于 添加位置的前一个节点，否则插入不了
		HeroNode temp = head;
		boolean flag = false; // flag标志添加的编号是否存在，默认为false
		while(temp.next != null) {
			
			if(temp.next.no > heroNode.no) { //位置找到，就在temp的后面插入
				break;
			} else if (temp.next.no == heroNode.no) {//说明希望添加的heroNode的编号已然存在
				
				flag = true; //说明编号存在
				break;
			}
			temp = temp.next; //后移，遍历当前链表
		}
		//判断flag 的值
		if(flag) { //不能添加，说明编号存在
			System.out.printf("准备插入的英雄的编号 %d 已经存在了, 不能加入\n", heroNode.no);
		} else {
			//插入到链表中, temp的后面
			heroNode.next = temp.next;
			temp.next = heroNode;
		}
	}
```



#### 【3】修改

**设置flag的思想很不错**，如果不设置flag，就需要在while循环中的temp.no == newHeroNode.no进行修改

```java
//1. 根据 newHeroNode 的 no 来修改即可
	public void update(HeroNode newHeroNode) {
		//判断是否空
		if(head.next == null) {
			System.out.println("链表为空~");
			return;
		}
		//找到需要修改的节点, 根据no编号
		//定义一个辅助变量
		HeroNode temp = head.next;
		boolean flag = false; //表示是否找到该节点
		while(true) {
			if (temp == null) {
				break; //已经遍历完链表
			}
			if(temp.no == newHeroNode.no) {
				//找到
				flag = true;
				break;
			}
			temp = temp.next;
		}
		//根据flag 判断是否找到要修改的节点
		if(flag) {
			temp.name = newHeroNode.name;
			temp.nickname = newHeroNode.nickname;
		} else { //没有找到
			System.out.printf("没有找到 编号 %d 的节点，不能修改\n", newHeroNode.no);
		}
	}
```

#### 【4】删除

temp.next = temp.next.next;



## 5、双链表（开发中更常用）

查找有序的双链表，很像二分，但不是二分

LinkedHashMap

## （1）增删改查

#### 【1】遍历 

和 单链表一样，只是可以向前，也可以向后查找

#### 【2】添加 

(默认添加到双向链表的最后)
(1) 先找到双向链表的最后这个节点

```java
 temp.next = newHeroNode
 newHeroNode.pre = temp;
```



#### 【3】先查询再插入

```java
heroNode.next = temp.next;
temp.next.pre=heroNode;
temp.next = heroNode;
heroNode.pre=temp
```



#### 【4】修改 

思路和 原来的单向链表一样.

#### 【5】删除

(1) 因为是双向链表，因此，我们可以实现自我删除某个节点
(2) 直接找到要删除的这个节点，比如temp
	

```java
			//如果删除的是头结点，头结点的pre是null
			if(temp!=head){
                temp.pre.next = temp.next;
            }
			
			// 如果是最后一个节点，就不需要执行下面这句话，否则出现空指针
			if (temp.next != null) {
				temp.next.pre = temp.pre;
			}
```



## 6、环形链表(约瑟夫环)

## 7、栈

表尾用来输入数据，通常也叫作栈顶（top）；相应地，表头就是栈底（bottom）。

### （1）应用场景

浏览器前进后退

表达式求值

括号匹配

子程序调用

二叉树的遍历

DFS

### （2）数组和链表实现

【1】数组

```
1. 定义一个 top  来表示栈顶，初始化 为  -1
2. 入栈的操作，当有数据加入到栈时， top++;  stack[top] = data;
3. 出栈的操作， int value = stack[top]; top--, return value
```

【2】链表

栈顶放在单链表的头部，需要增加指向栈顶的 top 指针，头插法入栈

在链式栈中进行删除操作时，只能在栈顶进行操作。因此，将栈顶的 top 指针指向栈顶元素的 next 指针即可完成删除。

![CgqCHl7Uy3aANCZjAABKDxPgTUQ478](img\CgqCHl7Uy3aANCZjAABKDxPgTUQ478.png)





![CgqCHl7Uy4iAUXORAACjOoEAXFA016](img\CgqCHl7Uy4iAUXORAACjOoEAXFA016.png)

### （3）前缀、中缀、后缀表达式

#### 【1】前缀表达式(波兰表达式)

 (3+4)×5-6 对应的前缀表达式就是 - × + 3 4 5 6

前缀表达式的计算机求值

从右至左扫描表达式，遇到数字时，将数字压入堆栈，遇到运算符时，弹出栈顶的两个数，用运算符对它们做相应的计算（栈顶元素 和 次顶元素），并将结果入栈；重复上述过程直到表达式最左端，最后运算得出的值即为表达式的结果

例如: (3+4)×5-6 对应的前缀表达式就是 - × + 3 4 5 6 , 针对前缀表达式求值步骤如下:

[1]从右至左扫描，将6、5、4、3压入堆栈
[2]遇到+运算符，因此弹出3和4（3为栈顶元素，4为次顶元素），计算出3+4的值，得7，再将7入栈
[3]接下来是×运算符，因此弹出7和5，计算出7×5=35，将35入栈
[4]最后是-运算符，计算出35-6的值，即29，由此得出最终结果

#### 【2】中缀

常见的运算表达式，如(3+4)×5-6，一般转成后缀表达式

#### 【3】后缀（逆波兰表达式）

(3+4)×5-6 对应的后缀表达式就是 3 4 + 5 × 6 –

### （4）常见面试题

#### 【1】基本计算器

1. 通过一个 index  值（索引），来遍历我们的表达式
2. 如果我们发现是一个数字, 就直接入数栈
3. 如果发现扫描到是一个符号,  就分如下情况
3.1 如果发现当前的符号栈为 空，就直接入栈
3.2 如果符号栈有操作符，就进行比较,如果当前的操作符的优先级小于或者等于栈中的操作符， 就需要从数栈中pop出两个数,在从符号栈中pop出一个符号，进行运算，将得到结果，入数栈，然后将当前的操作符入符号栈， 如果当前的操作符的优先级大于栈中的操作符， 就直接入符号栈.
4. 当表达式扫描完毕，就顺序的从 数栈和符号栈中pop出相应的数和符号，并运行.

5. 最后在数栈只有一个数字，就是表达式的结果

#### 【2】中缀转后缀

1) 初始化两个栈：**运算符栈s1和储存中间结果的栈s2**；
2) 从左至右扫描中缀表达式；
3) 遇到操作数时，将其压s2；
4) 遇到运算符时，比较其与s1栈顶运算符的优先级：
1.如果s1为空，或栈顶运算符为左括号“(”，则直接将此运算符入栈；
2.否则，若优先级比栈顶运算符的高，也将运算符压入s1；
3.否则，将s1栈顶的运算符弹出并压入到s2中，再次转到(4.1)与s1中新的栈顶运算符相比较；
5) 遇到括号时：(1) 如果是左括号“(”，则直接压入s1(2) 如果是右括号“)”，则依次弹出s1栈顶的运算符，并压入s2，直到遇到左括号为止，此时将这一对括号丢弃
6) 重复步骤2至5，直到表达式的最右边
7) 将s1中剩余的运算符依次弹出并压入s2
8)  依次弹出s2中的元素并输出，**结果的逆序即为中缀表达式对应的后缀表达式**

#### 【3】后缀表达式求值

从左至右扫描表达式，遇到数字时，将数字压入堆栈，遇到运算符时，弹出栈顶的两个数，用运算符对它们做相应的计算（次顶元素 和 栈顶元素），并将结果入栈；重复上述过程直到表达式最右端，最后运算得出的值即为表达式的结果

## 8、哈希

### （1）概念

<font color =red>**散列表用的是数组支持按照下标随机访问数据的特性**</font>，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。

我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据





![92c89a57e21f49d2f14f4424343a2773](img\92c89a57e21f49d2f14f4424343a2773.jpg)



![图片11](img\图片11.png)



<img src="img\微信截图_20200602102245.png" alt="微信截图_20200602102245" style="zoom:50%;" />

### （2）哈希算法

【1】概念

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。

MD5、SHA、CRC等哈希算法，也无法完全避免这种散列冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率

- 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；
- 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
- 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
- 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值

【2】应用

全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储

[1]安全加密

最常用于加密的哈希算法是 MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和 SHA（Secure Hash Algorithm，安全散列算法）。

[2]唯一标识

在海量的图库中，搜索一张图是否存在

可以给每一个图片取一个唯一标识，或者说信息摘要。比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。

如果还想继续提高效率，我们可以把每个图片的唯一标识，和相应的图片文件在图库中的路径信息，都存储在散列表中。当要查看某个图片是不是在图库中的时候，我们先通过哈希算法对这个图片取唯一标识，然后在散列表中查找是否存在这个唯一标识。

如果不存在，那就说明这个图片不在图库中；如果存在，我们再通过散列表中存储的文件路径，获取到这个已经存在的图片，跟现在要插入的图片做全量的比对，看是否完全一样。如果一样，就说明已经存在；如果不一样，说明两张图片尽管唯一标识相同，但是并不是相同的图片。

[3]数据校验

BT 下载软件校验文件

通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。我们在前面讲过，哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同。所以，当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。

[4]散列函数

[5]负载均衡

负载均衡算法有很多，比如轮询、随机、加权轮询等。那如何才能实现一个会话粘滞（session sticky）的负载均衡算法呢？也就是说，我们需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。

[6]数据分片

1. 如何统计“搜索关键词”出现的次数

   假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

   我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。

   这样，哈希值相同的搜索关键词就被分配到了同一个机器上。也就是说，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。

   

2. 如何快速判断图片是否在图库中

   我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。

   当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模。假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。

[7]分布式存储

我们为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。

我们有海量的数据需要缓存，所以一个缓存机器肯定是不够的。于是，我们就需要将数据分布在多台机器上。该如何决定将哪个数据放到哪个机器上呢？我们可以借用前面数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。但是，如果数据增多，原来的 10 个机器已经无法承受了，我们就需要扩容了，比如扩到 11 个机器，这时候麻烦就来了。

因为，这里并不是简单地加个机器就可以了。原来的数据是通过与 10 来取模的。比如 13 这个数据，存储在编号为 3 这台机器上。但是新加了一台机器中，我们对数据按照 11 取模，原来 13 这个数据就被分配到 2 号这台机器上了。

因此，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。所以，我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。这时候，**一致性哈希算法**就要登场了。

假设我们有 k 个机器，数据的哈希值的范围是[0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。

https://www.cnblogs.com/luxiaoxun/p/12573742.html

### （3）应用

bitmap和布隆过滤器



## 9、跳表

一种各方面性能都比较优秀的**动态数据结构**，可以支持快速地插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树。Redis 中的有序集合（Sorted Set）就是用跳表来实现的

（1）概念

这种链表加多级索引的结构，就是跳表，跳表中查询任意数据的时间复杂度就是 O(logn)，空间复杂度是 O(n)，插入、删除操作的时间复杂度也是 O(logn)，通过随机函数来维护前面提到的“平衡性”，就是索引之间的节点不能太多

图中的 down 表示 down 指针，指向下一级结点

![14753c824a5ee4a976ea799727adc78e](img\14753c824a5ee4a976ea799727adc78e.jpg)

# 三、非线性

## 1、树

### （1）概念

如果该二叉树的所有叶子节点都在最后一层，并且结点总数= **2^n -1** , n 为层数，则我们称为**满二叉树**。
如果该二叉树的所有叶子节点都在最后一层或者倒数第二层，而且最后一层的叶子节点在左边连续，倒数第二层的叶子节点在右边连续，我们称为**完全二叉树**。

![4094a733986073fedb6b9d03f877d71e](img\4094a733986073fedb6b9d03f877d71e.jpg)

![50f89510ad1f7570791dd12f4e9adeb4](img\50f89510ad1f7570791dd12f4e9adeb4.jpg)

### （2）遍历

遍历的时间复杂度是 O(n)。

#### 【1】递归

前序遍历（中左右）: 先输出父节点，再遍历左子树和右子树
中序遍历（左中右）: 先遍历左子树，再输出父节点，再遍历右子树
后序遍历（左右中）: 先遍历左子树，再遍历右子树，最后输出父节点

#### 【2】非递归（迭代）

需要用自定义的栈模拟递归时的系统栈，莫里斯遍历虽然空间复杂度降下来了，但是会修改整个二叉树的结构！

##### [1]前序遍历（中左右）

要想最终的顺序得到中左右，那么入栈的时候，就是右左中，可以简化，只放右节点

```java
		TreeNode cur = root;
		//第一次把root放进去，是为了好进第一个while循环，因为当节点走到树的右侧时，其实和左侧的套路一样
		stack.push(cur);
		while (!stack.isEmpty()) {
			TreeNode node = stack.pop();
			while (node != null) {
				result.add(node.val);
				if (node.right != null) {
					stack.push(node.right);
				}
				node = node.left;
			}
		}
```



##### [2]中序遍历（左中右）

每次都是节点的左节点入栈，所以当传入节点的右节点时，也要把这个节点的左边节点进行入栈

```java
while (cur != null || !stack.isEmpty()) {
			while (cur != null) {
				stack.push(cur);
				cur = cur.left;
			}
			TreeNode node = stack.pop();
			result.add(node.val);

			cur = node.right;
			while (cur != null) {
				stack.push(cur);
				cur = cur.left;
			}

		}
```

##### [3]后序遍历（左右中）

后序遍历要先从根节点一直找到左子树的最左边的节点，然后回退到根节点，这时，需要标注根节点flag=true，标明已经回退过一次，然后传入根节点的右子树，然后重复上述过程，如果栈里的节点的flag=true，那么标明左右子树都已经找到过

```java
TreeNode cur=root;
		
		Stack<Node> stack=new Stack<Node>();
		
		while(cur!=null||!stack.isEmpty()) {
			
			//一直找到左子树的最左边
			while (cur!=null) {
				Node node=new Node(cur, false);
				stack.push(node);
				cur=cur.left;
			}
			
			if (!stack.isEmpty()) {
				if (!stack.peek().flag) {
					cur=stack.peek().treeNode.right;
					//标明从左边的子树返回到了根节点
					stack.peek().flag=true;
					
				}else {
					result.add(stack.pop().treeNode.val);
					
				}
			}
			
			
		}
```

### （3）删除节点（普通二叉树）

如果删除的节点是叶子节点，则删除该节点
如果删除的节点是非叶子节点，则删除该子树.

### （4）顺序存储二叉树（堆）

**堆其实就是一种完全二叉树**

从数据存储来看，数组存储方式和树的存储方式可以相互转换，即数组可以转换成树，树也可以转换成数组，


<img src="img\微信截图_20200609131025.png" alt="微信截图_20200609131025" style="zoom:80%;" />

顺序存储二叉树的特点:

顺序二叉树通常只考虑完全二叉树
第n个元素的左子节点为  2 * n + 1 
第n个元素的右子节点为  2 * n + 2
第n个元素的父节点为  (n-1) / 2

n : 表示二叉树中的第几个元素(按0开始编号)



### （5）哈夫曼

#### 【1】哈夫曼树

给定n个权值作为n个叶子结点，构造一棵二叉树，若该树的带权路径长度(wpl)达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree), 还有的书翻译为霍夫曼树。

赫夫曼树是带权路径长度最短的树，权值较大的结点离根较近。

若规定根结点的层数为1，则从根结点到第L层结点的路径长度为L-1

树的带权路径长度：树的带权路径长度规定为**所有叶子结点的带权路径长度之和**，记为WPL(weighted path length) ,权值越大的结点离根结点越近的二叉树才是最优二叉树。

<img src="img\微信截图_20200609193130.png" alt="微信截图_20200609193130" style="zoom:60%;" />



构成赫夫曼树的步骤：
1.从小到大进行排序, 将每一个数据，每个数据都是一个节点 ， 每个节点可以看成是一颗最简单的二叉树
2.取出根节点权值最小的两颗二叉树 
3.组成一颗新的二叉树, 该新的二叉树的根节点的权值是前面两颗二叉树根节点权值的和  
4.再将这颗新的二叉树，以根节点的权值大小 再次排序， 不断重复  1-2-3-4 的步骤，直到数列中，所有的数据都被处理，就得到一颗赫夫曼树

#### 【2】赫夫曼编码

赫夫曼编码广泛地用于数据文件压缩。其压缩率通常在20%～90%之间
赫夫曼码是可变字长编码(VLC)的一种

字符的编码都不能是其他字符编码的前缀，符合此要求的编码叫做前缀编码， 即不能匹配到重复的编码

```
i like like like java do you like a java       // 共40个字符(包括空格)
d:1 y:1 u:1 j:2  v:2  o:2  l:4  k:4  e:4 i:5  a:5   :9  // 各个字符对应的个数
按照上面字符出现的次数构建一颗赫夫曼树, 次数作为权值
```

<img src="img\图片21.png" alt="图片21" style="zoom:80%;" />



## 2、BST（二叉搜索树、二叉排序树）

### （1）概念

对于二叉排序树的任何一个非叶子节点，要求左子节点的值比当前节点的值小，右子节点的值比当前节点的值大。
特别说明：如果有相同的值，可以将该节点放在左子节点或右子节点

### （2）中序遍历

中序遍历的结果就是从小到大排序,时间复杂度是 O(n)，非常高效

### （3）删除节点

【1】删除的是叶子节点，直接删除，将其父节点指针指向null

【2】删除的节点target只有一个子节点，将父节点指向target的指针 指向target的子节点

【3】删除的节点target有两个子节点：有以下两种方法删除节点

[1]找到target的左子树中最大的节点，替换要删除的节点

<img src="img\删除节点-左子树替换.gif" alt="删除节点-左子树替换" style="zoom:60%;" />

[2]找到target的右子树中最小的节点，替换要删除的节点

<img src="img\删除节点-右子树替换.gif" alt="删除节点-右子树替换" style="zoom:50%;" />

### （4）支持重复数据的二叉查找树

第一种方法比较容易。二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。

第二种方法，每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。当要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止。这样就可以把键值等于要查找值的所有节点都找出来。

![3f59a40e3d927f567022918d89590a5f](img\3f59a40e3d927f567022918d89590a5f.jpg)

### （5）时间复杂度

二叉查找树是一棵完全二叉树（或满二叉树）的情况下，不管操作是插入、删除还是查找，时间复杂度其实都跟树的高度成正比，也就是 O(height)

完全二叉树的高度小于等于 log2n

## 3、平衡二叉搜索树

### （1）概念

平衡二叉树也叫平衡二叉搜索树（Self-balancing binary search tree）， 可以保证查询效率较高。平衡二叉查找树的高度接近 logn，所以插入、删除、查找操作的时间复杂度也比较稳定，是 O(logn)。

具有以下特点：它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用**实现方法**有红黑树、AVL树、替罪羊树、Splay Tree（伸展树）、Treap（树堆）等

### （2）旋转

【1】左旋转：围绕某个节点的左旋

降低右子树的高度

```java
当(节点4的右子树的高度)-(节点4的左子树的高度)>1时，需要降低右子树的高度，进行左旋转
[1]创建一个新的节点newNode，newNode.value=4
[2]newNode.left=4.left
[3]newNode.right=4.right.left
[4]4.value=4.right.value
[5]4.left=newNode
[6]4.right=4.right.right
```

<img src="img\微信截图_20200722180725.png" alt="微信截图_20200722180725" style="zoom:50%;" />

【2】右旋转

```java
当(节点10的左子树的高度)-(节点10的右子树的高度)>1时，需要降低左子树的高度，进行右旋转
[1]创建一个新的节点newNode，newNode.value=10
[2]newNode.left=10.left.right
[3]newNOde.right=10.right.right
[4]10.value=10.left.value
[5]10.left=10.left.left
[6]10.right=newNode
```

<img src="img\微信截图_20200722182648.png" alt="微信截图_20200722182648" style="zoom:80%;" />

【3】双旋转

```java
当符合右旋转的条件时，即10的左子树的高度-10的右子树的高度>1
[1]如果7的右子树的高度>7的左子树的高度，需要对7进行左旋转
[2]之后再对10进行右旋转
    
当符合左旋转的条件时，即10的右子树的高度-10的左子树的高度>1
[1]如果7的左子树的高度>7的右子树的高度，需要对7进行右旋转
[2]之后再对10进行左旋转
```

<img src="img\微信截图_20200722183831.png" alt="微信截图_20200722183831" style="zoom:50%;" />

### （3）红黑树

红黑树的英文是“Red-Black Tree”，简称 R-B Tree。它是一种不严格的平衡二叉查找树

红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：

- 根节点是黑色的；
- 每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；
- 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的，指的是树的边，而不是左右；
- 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

![903ee0dcb62bce2f5b47819541f9069a](img\903ee0dcb62bce2f5b47819541f9069a.jpg)

红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。

因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。不过，它实现起来比较复杂，如果自己写代码实现，难度会有些高，这个时候，我们其实更倾向用跳表来替代它。

#### 【1】插入

红黑树规定，插入的节点必须是红色的。而且，二叉查找树中新插入的节点都是放在叶子节点上。

关于插入操作的平衡调整，有这样两种特殊情况

- 如果插入节点的父节点是黑色的，那我们什么都不用做，它仍然满足红黑树的定义。
- 如果插入的节点是根节点，那我们直接改变它的颜色，把它变成黑色就可以了。

其他情况都会违背红黑树的定义，于是我们就需要进行调整，调整的过程包含两种基础的操作：**左右旋转和改变颜色**。



## 4、B树

### （1）概念

允许每个节点可以有更多的数据项和更多的子节点，就是多叉树

如图B树通过重新组织节点， 降低了树的高度

文件系统及数据库系统的设计者利用了磁盘预读原理，将一个节点的大小设为等于一个页(页得大小通常为4k)，这样每个节点只需要一次I/O就可以完全载入

### （2）2-3树

2-3树是最简单的B树结构, 2-3树是由二节点和三节点构成的树。具有如下特点:
2-3树的所有叶子节点都在同一层.(只要是B树都满足这个条件)
有两个子节点的节点叫二节点，二节点要么没有子节点，要么有两个子节点.
有三个子节点的节点叫三节点，三节点要么没有子节点，要么有三个子节点.

当按照规则插入一个数到某个节点时，不能满足上面三个要求，就需要拆，先向上拆，如果上层满，则拆本层，拆后仍然需要满足上面3个条件

<img src="img\微信截图_20200722223234.png" alt="微信截图_20200722223234" style="zoom:80%;" />

### （3）2-3-4树

![微信截图_20200722223336](img\微信截图_20200722223336.png)

### （4）B树、B+树和B*树

#### 【1】B树

B-tree树即B树，B即Balanced，平衡的意思。有人把B-tree翻译成B-树，容易让人产生误解。会以为B-树是一种树，而B树又是另一种树。实际上，B-tree就是指的B树。

```
B树的阶：节点的最多子节点个数。比如2-3树的阶是3，2-3-4树的阶是4
B-树的搜索，从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点

关键字集合分布在整颗树中, 即叶子节点和非叶子节点都存放数据.
搜索有可能在非叶子结点结束
其搜索性能等价于在关键字全集内做一次二分查找
```

<img src="img\微信截图_20200722230203.png" alt="微信截图_20200722230203" style="zoom:50%;" />



#### 【2】B+树

B+树是B树的变体，也是一种多路搜索树。**MySQL数据库索引**

论上讲，对跳表稍加改造，也可以替代 B+ 树，作为数据库的索引实现的。

```
B+树的搜索与B树也基本相同，区别是B+树只有达到叶子结点才命中（B树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找
所有关键字都出现在叶子结点的链表中（即数据只能在叶子节点【也叫稠密索引】），且链表中的关键字(数据)恰好是有序的。
不可能在非叶子结点命中
非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层
更适合文件索引系统
B树和B+树各有自己的应用场景，不能说B+树完全比B树好，反之亦然.

而 B 树实际上是低级版的 B+ 树，或者说 B+ 树是 B 树的改进版。B 树跟 B+ 树的不同点主要集中在这几个地方：B+ 树中的节点不存储数据，只是索引，而 B 树中的节点存储数据；
B 树中的叶子节点并不需要链表来串联。
也就是说，B 树只是一个每个节点的子节点个数不能小于 m/2 的 m 叉树。

```





![25700c1dc28ce094eed3ffac394531f4](img\25700c1dc28ce094eed3ffac394531f4.jpg)

如果我们要求某个区间的数据。我们只需要拿区间的起始值，在树中进行查找，当查找到某个叶子节点之后，我们再顺着链表往后遍历，直到链表中的结点数据值大于区间的终止值为止。所有遍历到的数据，就是符合区间值的所有数据。

我们要为几千万、上亿的数据构建索引，如果将索引存储在内存中，尽管内存访问的速度非常快，查询的效率非常高，但是，占用的内存会非常多。

我们可以借助时间换空间的思路，把索引存储在硬盘中，而非内存中。

比起内存读写操作，磁盘 IO 操作非常耗时，所以我们优化的重点就是尽量减少磁盘 IO 操作，也就是，尽量降低树的高度。那如何降低树的高度呢？

```java

/**
 * 这是B+树非叶子节点的定义。
 *
 * 假设keywords=[3, 5, 8, 10]
 * 4个键值将数据分为5个区间：(-INF,3), [3,5), [5,8), [8,10), [10,INF)
 * 5个区间分别对应：children[0]...children[4]
 *
 * m值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小：
 * PAGE_SIZE = (m-1)*4[keywordss大小]+m*8[children大小]
 */
public class BPlusTreeNode {
  public static int m = 5; // 5叉树
  public int[] keywords = new int[m-1]; // 键值，用来划分数据区间
  public BPlusTreeNode[] children = new BPlusTreeNode[m];//保存子节点指针
}

/**
 * 这是B+树中叶子节点的定义。
 *
 * B+树中的叶子节点跟内部节点是不一样的,
 * 叶子节点存储的是值，而非区间。
 * 这个定义里，每个叶子节点存储3个数据行的键值及地址信息。
 *
 * k值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小：
 * PAGE_SIZE = k*4[keyw..大小]+k*8[dataAd..大小]+8[prev大小]+8[next大小]
 */
public class BPlusTreeLeafNode {
  public static int k = 3;
  public int[] keywords = new int[k]; // 数据的键值
  public long[] dataAddress = new long[k]; // 数据地址

  public BPlusTreeLeafNode prev; // 这个结点在链表中的前驱结点
  public BPlusTreeLeafNode next; // 这个结点在链表中的后继结点
}
```



对于相同个数的数据构建 m 叉树索引，m 叉树中的 m 越大，那树的高度就越小，那 m 叉树中的 m 是不是越大越好呢？到底多大才最合适呢？不管是内存中的数据，还是磁盘中的数据，操作系统都是按页（一页大小通常是 4KB，这个值可以通过 getconfig PAGE_SIZE 命令查看）来读取的，一次会读一页的数据。如果要读取的数据量超过一页的大小，就会触发多次 IO 操作。所以，<font color=red>**我们在选择 m 大小的时候，要尽量让每个节点的大小等于一个页的大小**</font>。读取一个节点，只需要一次磁盘 IO 操作。

索引有利也有弊，它也会让写入数据的效率下降。数据的写入过程，会涉及索引的更新，这是索引导致写入变慢的主要原因。我们在删除某个数据的时候，也要对应地更新索引节点。势必会影响索引的效率。



B+ 树的特点：

- 每个节点中子节点的个数不能超过 m，也不能小于 m/2；
- 根节点的子节点个数可以不超过 m/2，这是一个例外；
- m 叉树只存储索引，并不真正存储数据，这个有点儿类似跳表；
- 通过链表将叶子节点串联在一起，这样可以方便按区间查找；
- 一般情况，根节点会被存储在内存中，其他节点存储在磁盘中。

<img src="img\微信截图_20200722230307.png" alt="微信截图_20200722230307" style="zoom:50%;" />

#### 【3】B*树

B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针。

```
B*树定义了非叶子结点关键字个数至少为(2/3)*M，其中M是度，即块的最低使用率为2/3，而B+树的块的最低使用率为B+树的1/2。

从第1个特点我们可以看出，B*树分配新结点的概率比B+树要低，空间使用率更高

```



<img src="img\微信截图_20200722230409.png" alt="微信截图_20200722230409" style="zoom:50%;" />





## 6、递归树

借助递归树来分析递归算法的时间复杂度

（1）斐波那契数列的递归树

![1d9648b7f43e430473d76d24803159a3](img\1d9648b7f43e430473d76d24803159a3.jpg)

（2）归并排序的递归树

我们只需要知道这棵树的高度 h，用高度 h 乘以每一层的时间消耗 n，就可以得到总的时间复杂度 O(n∗h)，

归并排序递归树是一棵满二叉树。我们前两节中讲到，满二叉树的高度大约是 log2n，所以，归并排序递归实现的时间复杂度就是 O(nlogn)

![c66bfc3d02d3b7b8f64c208bf4c948d0](img\c66bfc3d02d3b7b8f64c208bf4c948d0.jpg)

## 7、堆

### （1）概念

堆是一种特殊的树。

- 堆是一个完全二叉树；
- 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值

![4d349f57947df6590a2dd1364c3b0b1e](img\4d349f57947df6590a2dd1364c3b0b1e.jpg)

### （2）插入、删除

堆化实际上有两种，从下往上和从上往下

【1】插入

从下往上

我们可以让新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，我们就互换两个节点。

![e3744661e038e4ae570316bc862b2c0e](img\e3744661e038e4ae570316bc862b2c0e.jpg)

【2】删除

从上往下

我们把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。

![110d6f442e718f86d2a1d16095513260](img\110d6f442e718f86d2a1d16095513260.jpg)

### （3）建堆和堆排序

【1】建堆

我们首先将数组原地建成一个堆。所谓“原地”就是，不借助另一个数组，就在原数组上操作。建堆的过程，有两种思路。

第一种是借助我们前面讲的，在堆中插入一个元素的思路。尽管数组中包含 n 个数据，但是我们可以假设，起初堆中只包含一个数据，就是下标为 1 的数据。然后，我们调用前面讲的插入操作，将下标从 2 到 n 的数据依次插入到堆中。这样我们就将包含 n 个数据的数组，组织成了堆。

第二种实现思路，跟第一种截然相反。第一种建堆思路的处理过程是从前往后处理数组数据，并且每个数据插入堆中时，都是从下往上堆化。而第二种实现思路，是从后往前处理数组，并且每个数据都是从上往下堆化。

![50c1e6bc6fe68378d0a66bdccfff441e](img\50c1e6bc6fe68378d0a66bdccfff441e.jpg)



![aabb8d15b1b92d5e040895589c60419d](img\aabb8d15b1b92d5e040895589c60419d.jpg)

建堆过程的时间复杂度是 O(n)

【2】排序

把它跟最后一个元素交换，那最大元素就放到了下标为 n 的位置。这个过程有点类似上面讲的“删除堆顶元素”的操作，当堆顶元素移除之后，我们把下标为 n 的元素放到堆顶，然后再通过堆化的方法，将剩下的 n−1 个元素重新构建成堆。堆化完成之后，我们再取堆顶的元素，放到下标是 n−1 的位置，一直重复这个过程，直到最后堆中只剩下标为 1 的一个元素，排序工作就完成了。

排序过程的时间复杂度是 O(nlogn)

### （4）应用

优先级队列、求 Top K 和求中位数

[1]优先队列

一个堆就可以看作一个优先级队列。很多时候，它们只是概念上的区分而已。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。

应用：赫夫曼编码、图的最短路径、最小生成树算法

[2]求 Top K

求 Top K 的问题抽象成两类。一类是针对静态数据集合，也就是说数据集合事先确定，不会再变。另一类是针对动态数据集合，也就是说数据集合事先并不确定，有数据动态地加入到集合中。

[3]快速求出中位数，还可以快速求其他百分位的数据

## 8、图

### （1）表示方式

#### 【1】邻接矩阵

邻接矩阵是表示图形中顶点之间相邻关系的矩阵，对于n个顶点的图而言，矩阵是的row和col表示的是1....n个点。



无向图：

![微信截图_20200723163640](img\微信截图_20200723163640.png)



有向图

<img src="img\微信截图_20200724095537.png" alt="微信截图_20200724095537" style="zoom:80%;" />

代码：

```
[1]ArrayList存储顶点
[2]int[][]保存邻接矩阵
```

#### 【2】邻接表

邻接表的实现只关心存在的边，不关心不存在的边。因此没有空间浪费，邻接表由数组+链表组成

无向图：

![微信截图_20200723163745](img\微信截图_20200723163745.png)



![微信截图_20200724095934](img\微信截图_20200724095934.png)



有向图

![微信截图_20200724100758](img\微信截图_20200724100758.png)



代码

```
[1]ArrayList保存顶点
[2]链表保存边
```

#### 【3】逆邻接表

在微博好友关系中，查看粉丝，就用到了逆邻接表

![501440bcffdcf4e6f9a5ca1117e990a1](img\501440bcffdcf4e6f9a5ca1117e990a1.jpg)

### （2）遍历

#### 【1】DFS

**最直观的例子就是“走迷宫”**

深度优先搜索用的是一种比较著名的算法思想，回溯思想。这种思想解决问题的过程，非常适合用递归来实现。

深度优先遍历，从初始访问结点出发，初始访问结点可能有多个邻接结点，深度优先遍历的策略就是首先访问第一个邻接结点，然后再以这个被访问的邻接结点作为初始结点，访问它的第一个邻接结点， 可以这样理解：每次都在访问完当前结点后首先访问当前结点的第一个邻接结点。



![微信截图_20200724172011](img\微信截图_20200724172011.png)



邻接矩阵：O(n^2)

邻接表：O(n+e)， e：边的数量

#### 【2】BFS

**s 表示起始顶点，t 表示终止顶点。我们搜索一条从 s 到 t 的路径。实际上，这样求得的路径就是从 s 到 t 的最短路径。**

![搜狗截图20年07月26日2030_1](img\搜狗截图20年07月26日2030_1.png)

邻接矩阵：O(n^2)

邻接表：O(n+e)， e：边的数量

# 四、算法

## 1、回溯与递归

递归就是方法自己调用自己,每次调用时**传入不同的变量**.递归有助于编程者解决复杂的问题,同时可以让代码变得简洁

递归的实现包含了两个部分，一个是递归主体，另一个是终止条件。

**递归的数学模型其实就是数学归纳法，写出递归代码的关键在于，写出递推公式和找出终止条件。**

与数学归纳法类似，当采用递归算法解决问题时，我们也需要围绕这 2 个步骤去做文章：

[1]当你面对一个大规模问题时，如何把它分解为几个小规模的同样的问题；

[2]当你把问题通过多轮分解后，最终的结果，也就是终止条件如何定义。

所以当一个问题同时满足以下 2 个条件时，就可以使用递归的方法求解：

[1]可以拆解为除了数据规模以外，求解思路完全相同的子问题；

[2]存在终止条件。

**编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤**

**不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式**

### （1）应用场景

DFS 深度优先搜索、前中后序二叉树遍历

各种数学问题如: 8皇后问题 , 汉诺塔, 阶乘问题, 迷宫问题(回溯), 球和篮子的问题(google编程大赛)

正则表达式匹配、编译原理中的语法分析

数独、0-1 背包、图的着色、旅行商问题、全排列

各种算法中也会使用到递归，比如快排，归并排序，二分查找，分治算法等.

将用栈解决的问题-->递归代码比较简洁

### （2）递归需要遵守的重要规则

1）执行一个方法时，就创建一个新的受保护的独立空间(栈空间)
2）方法的局部变量是独立的，不会相互影响, 比如n变量
3）如果方法中使用的是**引用类型变量**(比如**数组**)，就会共享该引用类型的数据.
4）递归**必须向退出递归的条件逼近**，否则就是无限递归,出现StackOverflowError，死龟了:)
5）当一个方法执行完毕，或者遇到return，就会返回，遵守谁调用，就将结果返回给谁，同时当方法执行完毕或者返回时，该方法也就执行完毕。

### （3）回溯的处理思想

有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。

回溯算法非常适合用递归来实现，在实现的过程中，**剪枝操作**是提高回溯效率的一种技巧。利用剪枝，我们并不需要穷举搜索所有的情况，从而提高搜索效率。

### （4）经典面试题

#### 【1】迷宫

#### 【2】8皇后

1）第一个皇后先放第一行第一列
2）第二个皇后放在第二行第一列、然后判断是否OK， 如果不OK，继续放在第二列、第三列、依次把所有列都放完，找到一个合适
3）继续第三个皇后，还是第一列、第二列……直到第8个皇后也能放在一个不冲突的位置，算是找到了一个正确解
4）**当得到一个正确解时，在栈回退到上一个栈时，就会开始回溯，即将第一个皇后，放到第一列的所有正确解，全部得到**.
5）然后回头继续第一个皇后放第二列，后面继续循环执行 1,2,3,4的步骤

说明：理论上应该创建一个二维数组来表示棋盘，但是实际上可以通过算法，用一个**一维数组**即可解决问题. arr[8] = {0 , 4, 7, 5, 2, 6, 1, 3} ，arr[i] = val , 表示第i+1个皇后，放在第i+1行的第val+1列

第1个皇后放在第1行的第1列
第2个皇后放在第2行的第5列
第3个皇后放在第3行的第8列
第4个皇后放在第4行的第6列
第5个皇后放在第5行的第3列
第6个皇后放在第6行的第7列
第7个皇后放在第7行的第2列
第8个皇后放在第8行的第4列

#### 【3】马踏棋盘算法

```
将马随机放在国际象棋的8×8棋盘Board[0～7][0～7]的某个方格中，马按走棋规则(马走日字)进行移动。要求每个方格只进入一次，走遍棋盘上全部64个方格
```

![微信截图_20200814103450](img\微信截图_20200814103450.png)



## 2、贪心算法

### （1）概念

贪婪算法(贪心算法)是指在对问题进行求解时，在每一步选择中都采取最好或者最优(即最有利)的选择，从而希望能够导致结果是最好或者最优的算法

贪婪算法所得到的结果不一定是最优的结果(有时候会是最优解)，但是都是相对近似(接近)最优解的结果

### （2）步骤

贪心算法解决问题的步骤：

第一步，当我们看到这类问题的时候，首先要联想到贪心算法：**针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。**

第二步，我们尝试看下这个问题是否可以用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。

第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。

```
假设存在下面需要付费的广播台，以及广播台信号可以覆盖的地区。 如何选择最少的广播台，让所有的地区都可以接收到信号

遍历所有的广播电台, 找到一个覆盖了最多未覆盖的地区的电台(此电台可能包含一些已覆盖的地区，但没有关系） 
将这个电台加入到一个集合中(比如ArrayList), 想办法把该电台覆盖的地区在下次比较时去掉。
重复第1步直到覆盖了全部的地区
```

![微信截图_20200803170534](img\微信截图_20200803170534.png)

### （3）应用

霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法



## 3、动态规划

动态规划比较适合用来求解最优问题，比如求最大值、最小值等等

动态规划(Dynamic Programming)算法的核心思想是：将大问题划分为小问题进行解决，从而一步步获取最优解的处理算法

动态规划算法与分治算法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。

与分治法不同的是，**适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的**。 ( 即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解 )

动态规划可以通过**填表（二维数组）**的方式来逐步推进，得到最优解.



**多阶段决策最优解模型**

一般而言，具有如下几个特征的问题，可以采用动态规划求解：

[1]最优子结构。它的含义是，**原问题的最优解所包括的子问题的解也是最优的**。例如，某个策略使得 A 到 G 是最优的。假设它途径了 Fi，那么它从 A 到 Fi 也一定是最优的。

[2]无后效性。某阶段的决策，无法影响先前的状态。可以理解为今天的动作改变不了历史。

[3]有重叠子问题。也就是，子问题之间不独立。这个性质是动态规划区别于分治法的条件。如果原问题不满足这个特征，也是可以用动态规划求解的，无非就是杀鸡用了宰牛刀。



### （1）方法

**在动态规划的过程中，是从后往前不断地推进结果，这就是状态转移的过程**

下面的 k 表示多轮决策的第 k 轮

![微信截图_20200819150000](img\微信截图_20200819150000.png)

解决动态规划问题，一般有两种思路。我把它们分别叫作，状态转移表法和状态转移方程法。

#### 【1】状态转移表法

状态表一般都是二维的，所以你可以把它想象成二维数组。其中，每个状态包含三个变量，行、列、数组值。我们根据决策的先后过程，从前往后，根据递推关系，分阶段填充状态表中的每个状态。最后，我们将这个递推填表的过程，翻译成代码，就是动态规划代码了。

**回溯算法实现 - 定义状态 - 画递归树 - 找重复子问题 - 画状态转移表 - 根据递推关系填表 - 将填表过程翻译成代码**

根据回溯算法的代码实现，我们可以画出递归树，看是否存在重复子问题。如果存在重复子问题，那我们就可以考虑能否用动态规划来解决；**如果不存在重复子问题，那回溯就是最好的解决方法。**

#### 【2】状态转移方程法

状态转移方程法有点类似递归的解题思路。我们需要分析，某个问题如何通过子问题来递归求解，也就是所谓的最优子结构。根据最优子结构，写出递归公式，也就是所谓的状态转移方程。有了状态转移方程，代码实现就非常简单了。一般情况下，我们有两种代码实现方法，一种是递归加“备忘录”，另一种是迭代递推。

**找最优子结构 - 写状态转移方程 - 将状态转移方程翻译成代码**

### （2）背包

背包问题主要是指一个给定容量的背包、若干具有一定价值和重量的物品，如何选择物品放入背包使物品的价值最大。

【1】0-1背包

要求装入的物品不能重复

解决思路：

我们把整个求解过程分为 n 个阶段，每个阶段会决策一个物品是否放到背包中。每个物品决策（放入或者不放入背包）完之后，背包中的物品的重量会有多种情况，也就是说，会达到多种不同的状态，对应到递归树中，就是有很多不同的节点。

```
每次遍历到的第i个物品，根据w[i]和v[i]来确定是否需要将该物品放入背包中。
即对于给定的n个物品，设v[i]、w[i]分别为第i个物品的价值和重量，C为背包的容量。
再令v[i][j]表示在前i个物品中能够装入容量为j的背包中的最大价值。也就是i、j、v[i][j]都有意义

(1) v[i][0]=v[0][j]=0; //表示 填入表 第一行和第一列是0，即v[i][0]代表背包里有i个物品，0个空间；v[0][j]代表背包里没有物品，有j的空间；所以数组的下标和物品以及重量的下标正好错开了0

(2) 当w[i]> j 时：v[i][j]=v[i-1][j]   // 当准备加入新增的商品的容量大于 当前背包的容量时，就直接使用上一个单元格的装入策略
(3) 当j>=w[i]时： v[i][j]=max{v[i-1][j], v[i]+v[i-1][j-w[i]]}  
// 当准备加入的新增的商品的容量小于等于当前背包的容量,
// 装入的方式:
v[i-1][j]： 就是上一个单元格的装入的最大值，如果不装入i，那么v[i][j]=v[i-1][j]
v[i] : 表示当前商品的价值 
v[i-1][j-w[i]] ： 要想把第i个物品装进去，就得把背包空出空间，所以用j-w[i]，否则背包就超了j；也就是说，v[i][j]依赖v[i-1][j-w[i]]，所以是动态规划


```



![微信截图_20200727191600](img\微信截图_20200727191600.png)



```
验证公式:
v[1][1] =1500
1. i = 1, j = 1 
2. w[i] = w[1] = 1
w [1] = 1  j = 1   v[i][j]=max{v[i-1][j], v[i]+v[i-1][j-w[i]]} : 
v[1][1] = max {v[0][1], v[1] + v[0][1-1]} = max{0, 1500 + 0} = 1500
v[3][4] 
1. i = 3；j = 4
w[i] = w[3] =3 j = 4
j = 4 >= w[i] = 3 => 4 >= 3

v[3][4] = max {v[2][4], v[3] + v[2][1]} = max{3000, 2000+1500} = 2000+1500
```

【2】完全背包

每种物品都有无限件可用，无限背包可以转化为01背包

### （3）四种算法总结

贪心、回溯、动态规划可以归为一类，而分治单独可以作为一类，因为它跟其他三个都不大一样。

回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。

在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。

贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过，它可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性（这里我们不怎么强调重复子问题）。其中，最优子结构、无后效性跟动态规划中的无异。“贪心选择性”的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，我们都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。

## 4、分治法

### （1）概念

**分治算法是一种处理问题的思想，递归是一种编程技巧**

分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。这个技巧是很多高效算法的基础，如排序算法(快速排序，归并排序)，傅立叶变换(快速傅立叶变换)……
分治算法可以求解的一些经典问题
二分搜索
大整数乘法
棋盘覆盖
合并排序
快速排序
线性时间选择
最接近点对问题
循环赛日程表
汉诺塔

### （2）特征

当你需要采用分治法时，一般原问题都需要具备以下几个特征：

1.难度在降低，即原问题的解决难度，随着数据的规模的缩小而降低。这个特征绝大多数问题都是满足的。

2.问题可分，原问题可以分解为若干个规模较小的同类型问题。这是应用分治法的前提。

3.**解可合并，利用所有子问题的解，可合并出原问题的解。这个特征很关键，能否利用分治法完全取决于这个特征**。

4.相互独立，各个子问题之间相互独立，某个子问题的求解不会影响到另一个子问题。如果子问题之间不独立，则分治法需要重复地解决公共的子问题，造成效率低下的结果。

根据前面我们对分治法的分析，你一定能迅速联想到递归。分治法需要递归地分解问题，再去解决问题。因此，分治法在每轮递归上，都包含了分解问题、解决问题和合并结果这 3 个步骤。

**分治算法一般都是用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧**

### （3）步骤

分治法在每一层递归上都有三个步骤：
分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题
解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题
合并：将各个子问题的解合并为原问题的解。

```
if |P|≤n0
   then return(ADHOC(P))
//将P分解为较小的子问题 P1 ,P2 ,…,Pk
for i←1 to k
do yi ← Divide-and-Conquer(Pi)   递归解决Pi
T ← MERGE(y1,y2,…,yk)   合并子问题
return(T)

```

其中|P|表示问题P的规模；n0为一阈值，表示当问题P的规模不超过n0时，问题已容易直接解出，不必再继续分解。ADHOC(P)是该分治法中的基本子算法，用于直接解小规模的问题P。因此，当P的规模不超过n0时直接用算法ADHOC(P)求解。算法MERGE(y1,y2,…,yk)是该分治法中的合并子算法，用于将P的子问题P1 ,P2 ,…,Pk的相应的解y1,y2,…,yk合并为P的解。

### （4）思路

[1]二分查找的时间复杂度是 O(logn)，这也是分治法普遍具备的特性。当你面对某个代码题，而且约束了时间复杂度是 O(logn) 或者是 O(nlogn) 时，可以想一下分治法是否可行。

[2]二分查找的循环次数并不确定。一般是达到某个条件就跳出循环。因此，编码的时候，多数会采用 while 循环加 break 跳出的代码结构。

[3]二分查找处理的原问题必须是有序的。因此，当你在一个有序数据环境中处理问题时，可以考虑分治法。相反，如果原问题中的数据并不是有序的，则使用分治法的可能性就会很低了。

### （5）汉诺塔

```
[1]如果是有一个盘， A->C

[2]如果我们有 n >= 2 情况，我们总是可以看做是两个盘 1.最下边的盘 2. 上面的盘

先把 最上面的盘 A->B
把最下边的盘 A->C
把B塔的所有盘 从 B->C   

```



## 5、排序

### （1）种类

<img src="img\微信截图_20200526111639.png" alt="微信截图_20200526111639" style="zoom:80%;" />



![fb8394a588b12ff6695cfd664afb17cd](img\fb8394a588b12ff6695cfd664afb17cd.jpg)



### （2）排序算法的时间复杂度

![图片2](img\图片2.png)





稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面；
不稳定：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；

**稳定排序很重要**

例子：要给电商交易系统中的“订单”排序。订单有两个属性，一个是下单时间，另一个是订单金额。如果我们现在有 10 万条订单数据，我们希望按照金额从小到大对订单数据排序。对于金额相同的订单，我们希望按照下单时间从早到晚有序。

解决思路是这样的：我们**先按照下单时间给订单排序**，注意是按照下单时间，不是金额。排序完成之后，我们用稳定排序算法，按照订单金额重新排序。



内排序：所有排序操作都在内存中完成；
外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行；

时间复杂度： 一个算法执行所耗费的时间。
空间复杂度：运行完一个程序所需内存的大小。
n: 数据规模
k: “桶”的个数
In-place:    不占用额外内存
Out-place: 占用额外内存



![图片6](img\图片6.png)



![1f6ef7e0a5365d6e9d68f0ccc71755fd](img\1f6ef7e0a5365d6e9d68f0ccc71755fd.jpg)

### （3）冒泡排序

冒泡排序（Bubble Sorting）的基本思想是：通过对待排序序列从前向后（从下标较小的元素开始）,依次**比较**
**相邻元素**的值，若发现逆序则交换，使值较大的元素逐渐从前移向后部，就象水底下的气泡一样逐渐向上冒

因为排序的过程中，各元素不断接近自己的位置，如果一趟比较下来**没有进行过交换，就说明序列有序**，因此要在排序过程中设置一个标志flag判断元素是否进行过交换。从而减少不必要的比较

冒泡排序过程中，当元素相同时不做交换，所以冒泡排序是稳定的排序算法

### （4）选择排序

第一次从arr[0]~arr[n-1]中选取最小值，与arr[0]交换，

第二次从arr[1]~arr[n-1]中选取最小值，与arr[1]交换，

第三次从arr[2]~arr[n-1]中选取最小值，与arr[2]交换，

第i次从arr[i-1]~arr[n-1]中选取最小值，与arr[i-1]交换，

第n-1次从arr[n-2]~arr[n-1]中选取最小值，与arr[n-2]交换，

总共通过n-1次，得到一个按排序码从小到大排列的有序序列。

**先遍历搜索找到最小值，与arr[i]交换**

比如 5，8，5，2，9 这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了，所以就不稳定了。正是因此，相对于冒泡排序和插入排序，选择排序就稍微逊色了。

### （5）插入排序



![图片7](H:/mycode4test/AlgorithmNew/img/图片7.png)

### （6）希尔排序

希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序。

<img src="H:/mycode4test/AlgorithmNew/img/图片8.png" alt="图片8" style="zoom:70%;" />

希尔排序时， 对有序序列在插入时采用交换法（冒泡）, 
希尔排序时， 对有序序列在插入时采用移动法（插入）,



### （7）快速排序 

快速排序（Quicksort）是对冒泡排序的一种改进。基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列



在快排的最好时间的复杂度下，如果每次选取分区点时，都能选中中位数，把数组等分成两个，那么此时的时间复杂度和归并一样，都是 O(n*logn)。

而在最坏的时间复杂度下，也就是如果每次分区都选中了最小值或最大值，得到不均等的两组。那么就需要 n 次的分区操作，每次分区平均扫描 n / 2 个元素，此时时间复杂度就退化为 O(n*n) 了。

【1】选取pivot的方法：

[1]三数取中法

我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”。

[2]随机法

随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。



快速排序法在大部分情况下，统计上是很难选到极端情况的。因此它平均的时间复杂度是 O(n*logn)。

快速排序法的空间方面，使用了交换法，因此空间复杂度为 O(1)。

很显然，快速排序的分区过程涉及交换操作，所以快排是不稳定的排序算法。



<img src="img/图片9.png" alt="图片9" style="zoom:80%;" />





一轮排序的过程

<img src="img\5644137-43b34643d2531ef1.jpg" alt="5644137-43b34643d2531ef1" style="zoom:80%;" />

### （8）堆排序

堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，它的最坏，最好，平均时间复杂度均为O(nlogn)，它也是不稳定排序。
堆是具有以下性质的**完全二叉树**：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆, 注意 : **没有要求结点的左孩子的值和右孩子的值的大小关系**。
每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆

**一般升序采用大顶堆，降序采用小顶堆** 

堆排序的基本思想是：
1.**将待排序序列构造成一个大顶堆**，**从最后的非叶子节点，依次从下到上**
2.此时，整个序列的最大值就是堆顶的根节点。
3.将其与末尾元素进行交换，此时末尾就为最大值。
4.然后将剩余n-1个元素重新构造成一个堆，而这个堆，只有根节点和第二层节点不满足大顶堆的条件，所以是从上到下进行调整，这样会得到n个元素的次大值。如此反复执行，便能得到一个有序序列了。

可以看到在构建大顶堆的过程中，元素的个数逐渐减少，最后就得到一个有序序列了.意思是**最后的数组就是从小到大的**，**当然也可以是从大到小**

### （9）归并排序

该算法采用经典的**分治**（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案"修补"在一起，即分而治之)。

对于归并排序，它采用了二分的迭代方式，复杂度是 logn。

每次的迭代，需要对两个有序数组进行合并，这样的动作在 O(n) 的时间复杂度下就可以完成。因此，**归并排序的复杂度就是二者的乘积 O(nlogn)。**同时，它的执行频次与输入序列无关，因此，归并排序最好、最坏、平均时间复杂度都是 O(nlogn)。

空间复杂度方面，由于每次合并的操作都需要开辟基于数组的临时内存空间，所以空间复杂度为 O(n)。归并排序合并的时候，相同元素的前后顺序不变，所以归并是稳定的排序算法。

<img src="img\图片3.png" alt="图片3" style="zoom:70%;" />

**归并排序可以采用递归去实现（也可采用迭代的方式去实现）。分阶段可以理解为就是递归拆分子序列的过程。**



<img src="img\图片4.png" alt="图片4" style="zoom:70%;" />



<img src="img\图片5.png" alt="图片5" style="zoom:67%;" />



```
left=0,mid=3,right=7
left=0,mid=1,right=3
left=0,mid=0,right=1
merge:left=0,mid=0,right=1
===============
left=2,mid=2,right=3
merge:left=2,mid=2,right=3
===============
merge:left=0,mid=1,right=3
===============
left=4,mid=5,right=7
left=4,mid=4,right=5
merge:left=4,mid=4,right=5
===============
left=6,mid=6,right=7
merge:left=6,mid=6,right=7
===============
merge:left=4,mid=5,right=7
===============
merge:left=0,mid=3,right=7
===============
```





### （10）桶排序（外部排序）



将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。

![987564607b864255f81686829503abae](img\987564607b864255f81686829503abae.jpg)



**要求：**

首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。

桶排序比较适合用在**外部排序**中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中

```
比如说我们有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。这个时候该怎么办呢？

我们可以先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后我们得到，订单金额最小是 1 元，最大是 10 万元。我们将所有订单根据金额划分到 100 个桶里，第一个桶我们存储金额在 1 元到 1000 元之内的订单，第二桶存储金额在 1001 元到 2000 元之内的订单，以此类推。每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名（00，01，02…99）。
理想的情况下，如果订单金额在 1 到 10 万之间均匀分布，那订单会被均匀划分到 100 个文件中，每个小文件中存储大约 100MB 的订单数据，我们就可以将这 100 个小文件依次放到内存中，用快排来排序。等所有文件都排好序之后，我们只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。
不过，你可能也发现了，订单按照金额在 1 元到 10 万元之间并不一定是均匀分布的 ，所以 10GB 订单数据是无法均匀地被划分到 100 个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。这又该怎么办呢？
针对这些划分之后还是比较大的文件，我们可以继续划分，比如，订单金额在 1 元到 1000 元之间的比较多，我们就将这个区间继续划分为 10 个小区间，1 元到 100 元，101 元到 200 元，201 元到 300 元…901 元到 1000 元。如果划分之后，101 元到 200 元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。
```

### （11）计数排序

```
根据年龄给 100 万用户排序，就类似按照成绩给 50 万考生排序。我们假设年龄的范围最小 1 岁，最大不超过 120 岁。我们可以遍历这 100 万用户，根据年龄将其划分到这 120 个桶里，然后依次顺序遍历这 120 个桶中的元素。这样就得到了按照年龄排序的 100 万用户数据。
```

当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

例子：

假设只有 8 个考生，分数在 0 到 5 分之间。这 8 个考生的成绩我们放在一个数组 A[8]中，它们分别是：2，5，3，0，2，3，0，3

考生的成绩从 0 到 5 分，我们使用大小为 6 的数组 C[6]表示桶，其中下标对应分数。不过，C[6]内存储的是对应的考生个数

![adc75672ef33fa54b023a040834fcbc9](img\adc75672ef33fa54b023a040834fcbc9.jpg)



![361f4d781d2a2d144dcbbbb0b9e6db29](img\361f4d781d2a2d144dcbbbb0b9e6db29.jpg)

那我们如何快速计算出，每个分数的考生在有序数组中对应的存储位置呢？

思路是这样的：我们对 C[6]数组顺序求和，C[6]存储的数据就变成了下面这样子。C[k]里存储小于等于分数 k 的考生个数。



![dd6c62b12b0dc1b3a294af0fa1ce371f](img\dd6c62b12b0dc1b3a294af0fa1ce371f.jpg)

我们从后到前依次扫描数组 A。比如，当扫描到 3 时，我们可以从数组 C 中取出下标为 3 的值 7，也就是说，到目前为止，包括自己在内，分数小于等于 3 的考生有 7 个，也就是说 3 是数组 R 中的第 7 个元素（也就是数组 R 中下标为 6 的位置）。当 3 放入到数组 R 中后，小于等于 3 的元素就只剩下了 6 个了，所以相应的 C[3]要减 1，变成 6。

![1d730cb17249f8e92ef5cab53ae65784](img\1d730cb17249f8e92ef5cab53ae65784.jpg)



**计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。**



还是拿考生这个例子。如果考生成绩精确到小数后一位，我们就需要将所有的分数都先乘以 10，转化成整数，然后再放到 9010 个桶内。再比如，如果要排序的数据中有负数，数据的范围是[-1000, 1000]，那我们就需要先对每个数据都加 1000，转化成非负整数。

### （12）基数排序

基数排序（radix sort）属于“分配式排序”（distribution sort），又称“桶子法”（bucket sort）或bin sort，顾名思义，它是通过键值的各个位的值，将要排序的元素分配至某些“桶”中，达到排序的作用

基数排序(Radix Sort)是桶排序的扩展

用空间换时间，容易内存溢出



```
假设我们有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序

假设要比较两个手机号码 a，b 的大小，如果在前面几位中，a 手机号码已经比 b 手机号码大了，那后面的几位就不用看了
先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。
```

![df0cdbb73bd19a2d69a52c54d8b9fc0c](img\df0cdbb73bd19a2d69a52c54d8b9fc0c.jpg)

```
排序牛津字典中的 20 万个英文单词

我们可以把所有的单词补齐到相同长度，位数不够的可以在后面补“0”，因为根据ASCII 值，所有字母都大于“0”，所以补“0”不会影响到原有的大小顺序。
```



**基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。**

## 6、查询搜索算法

1) 顺序(线性)查找
2) 二分查找/折半查找
3) 插值查找
4) 斐波那契查找（黄金分割点查找）

### （1）二分查找

大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决

```
有 1000 万个整数数据，每个数据占 8 个字节，如何设计数据结构和算法，快速判断某个整数是否出现在这 1000 万数据中？ 我们希望这个功能不要占用太多的内存空间，最多不要超过 100MB
```

看似数据很多，但实际上，1000万的8个字节数据，大小不到80MB，可以先读入内存，排序，再二分查找。

这里**不可以使用散列表、二叉树**，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。如果用散列表或者二叉树来存储这 1000 万的数据，用 100MB 的内存肯定是存不下的。

### （2）插值插值

```
插值查找算法类似于二分查找，不同的是插值查找每次从自适应mid处开始查找。
将折半查找中的求mid 索引的公式 , low 表示左边索引left, high表示右边索引right.key 就是前面我们讲的  findVal

int mid = low + (high - low) * (key - arr[low]) / (arr[high] - arr[low])  ;/*插值索引*/
对应前面的代码公式：int mid = left + (right – left) * (findVal – arr[left]) / (arr[right] – arr[left])
```



![QQ截图20200531204400](img\QQ截图20200531204400.png)

对于数据量较大，关键字**分布比较均匀**的查找表来说，采用插值查找, 速度较快.
关键字分布不均匀的情况下，该方法不一定比折半查找要好

### （3）斐波那契查找

黄金分割点是指把一条线段分割为两部分，使其中一部分与全长之比等于另一部分与这部分之比。取其前三位数字的近似值是0.618。由于按此比例设计的造型十分美丽，因此称为黄金分割，也称为中外比。这是一个神奇的数字，会带来意向不大的效果。
斐波那契数列 {1, 1, 2, 3, 5, 8, 13, 21, 34, 55 } 发现斐波那契数列的两个相邻数 的比例，无限接近 黄金分割值0.618

斐波那契查找原理与前两种相似，仅仅改变了中间结点（mid）的位置，mid不再是中间或插值得到，而是位于黄金分割点附近，即mid=low+F(k-1)-1（F代表斐波那契数列），如下图所示



![图片10](img\图片10.png)



由斐波那契数列 F[k]=F[k-1]+F[k-2] 的性质，可以得到 （F[k]-1）=（F[k-1]-1）+（F[k-2]-1）+1 。该式说明：只要顺序表的长度为F[k]-1，则可以将该表分成长度为F[k-1]-1和F[k-2]-1的两段，即如上图所示。从而中间位置为mid=low+F(k-1)-1           

类似的，每一子段也可以用相同的方式分割
但顺序表长度n不一定刚好等于F[k]-1，所以需要将原来的顺序表长度n增加至F[k]-1。这里的k值只要能使得F[k]-1恰好大于或等于n即可，由以下代码得到,顺序表长度增加后，新增的位置（从n+1到F[k]-1位置），都赋为n位置的值即可。

while(n>fib(k)-1)
    k++;



## 7、位运算

### （1）概念

字节：存储数据的单位用字节表示，8位无符号数（bit）代表1个字节（byte）

字符：不同编码里，字符和字节的对应关系不同

**①**ASCII码中，一个英文字母（不分大小写）占一个字节的空间，一个中文汉字占两个字节的空间。

**②**UTF-8编码中，一个英文字符等于一个字节，一个中文（含繁体）等于三个字节。

**③**Unicode编码中，一个英文等于两个字节，一个中文（含繁体）等于两个字节。

符号：英文标点占一个字节，中文标点占两个字节。

### （2）进制转换

2进制转8进制：从右往左，每3位为1组，不够的左边补0

2进制转16进制：从右往左，每4位为1组，不够的左边补0



```java
//二进制
int a=0b110;
//八进制
int b=0110;
//十六进制
int c=0x110;
二进制表示0b
八进制表示0
十六进制表示0x
```

十进制转二进制：数字除以2直到商为0，得到的结果倒序就是对应的2进制

### （3）原码、反码、补码、有符号数

有符号数：计算机内都是采用补码保存有符号数

原码：最高位是符号为，0代表正，1代表负，其余代表数字大小

反码：正数的反码与原码相同，负数的反码是符号位不变，其余位取反

补码：正数的补码与原码相同，负数的补码是反码+1

Byte类：-128~127 -2^7~2^7-1

Integer类：-2^31~2^31-1

Long类：-2^63~2^63-1

### （4）位运算

**<<表示左移移，不分正负数，低位补0；**

**>>表示右移，如果该数为正，则高位补0，若为负数，则高位补1；**

**>>>表示无符号右移，也叫逻辑右移，即若该数为正，则高位补0，而若该数为负数，则右移后高位同样补0**

```java
public static void main(String[] args) {
	     int a = 60; /* 60 = 0011 1100 */ 
	     int b = 13; /* 13 = 0000 1101 */
	     int c = 0;
	     c = a & b;       /* 12 = 0000 1100 */
	     System.out.println("a & b = " + c );
	 
	     c = a | b;       /* 61 = 0011 1101 */
	     System.out.println("a | b = " + c );
	 	//异或 同为0，异为1
	     c = a ^ b;       /* 49 = 0011 0001 */
	     System.out.println("a ^ b = " + c );
	 	//非
	     c = ~a;          /*-61 = 1100 0011 */
	     System.out.println("~a = " + c );
	 
	     c = a << 2;     /* 240 = 1111 0000 */
	     System.out.println("a << 2 = " + c );
	 
	     c = a >> 2;     /* 15 = 1111 */
	     System.out.println("a >> 2  = " + c );
	  
	     c = a >>> 2;     /* 15 = 0000 1111 */
	     System.out.println("a >>> 2 = " + c );
	  }

```



## 8、字符串匹配算法

### （1）BF 算法

BF 算法中的 BF 是 Brute Force 的缩写，中文叫作暴力匹配算法，也叫朴素匹配算法。

尽管理论上，BF 算法的时间复杂度很高，是 O(n*m)，但在实际的开发中，它却是一个比较常用的字符串匹配算法。为什么这么说呢？原因有两点。

第一，实际的软件开发中，大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。所以，尽管理论上的最坏情况时间复杂度是 O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。

第二，朴素字符串匹配算法思想简单，代码实现也非常简单。简单意味着不容易出错，如果有 bug 也容易暴露和修复。在工程中，在满足性能要求的前提下，简单是首选。这也是我们常说的KISS（Keep it Simple and Stupid）设计原则。

### （2）RK 算法

RK 算法的全称叫 Rabin-Karp 算法

我们通过哈希算法对主串中的 n-m+1 个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。如果某个子串的哈希值与模式串相等，那就说明对应的子串和模式串匹配了（这里先不考虑哈希冲突的问题，后面我们会讲到）。因为哈希值是一个数字，数字之间比较是否相等是非常快速的，所以模式串和子串比较的效率就提高了。

为了方便解释，在下面的讲解中，我假设字符串中只包含 a～z 这 26 个小写字符，我们用二十六进制来表示一个字符串，对应的哈希值就是二十六进制数转化成十进制的结果。

![d5c1cb11d9fc97d0b28513ba7495ab04](img\d5c1cb11d9fc97d0b28513ba7495ab04.jpg)



![c47b092408ebfddfa96268037d53aa9c](img\c47b092408ebfddfa96268037d53aa9c.jpg)



26^(m-1) 这部分的计算，我们可以通过查表的方法来提高效率。我们事先计算好 26^0、26^1、26^2……26^(m-1)，并且存储在一个长度为 m 的数组中，公式中的“次方”就对应数组的下标。

![224b899c6e82ec54594e2683acc4552f](img\224b899c6e82ec54594e2683acc4552f.jpg)



RK 算法整体的时间复杂度就是 O(n)。

模式串很长，相应的主串中的子串也会很长，通过上面的哈希算法计算得到的哈希值就可能很大，如果超过了计算机中整型数据可以表示的范围，那该如何解决呢？

我们可以把字符串中每个字母对应的数字相加，最后得到的和作为哈希值。这种哈希算法产生的哈希值的数据范围就相对要小很多了。不过，你也应该发现，这种哈希算法的哈希冲突概率也是挺高的。当然，我只是举了一个最简单的设计方法，还有很多更加优化的方法，比如将每一个字母从小到大对应一个素数，而不是 1，2，3……这样的自然数，这样冲突的概率就会降低一些。

当我们发现一个子串的哈希值跟模式串的哈希值相等的时候，我们只需要再对比一下子串和模式串本身就好了。当然，如果子串的哈希值与模式串的哈希值不相等，那对应的子串和模式串肯定也是不匹配的，就不需要比对子串和模式串本身了。

### （3）BM算法

性能是著名的KMP 算法的 3 到 4 倍

BM 算法包含两部分，分别是坏字符规则（bad character rule）和好后缀规则（good suffix shift）

#### 【1】坏字符规则

BM 算法的匹配顺序比较特别，它是按照模式串下标从大到小的顺序，倒着匹配的。我们从模式串的末尾往前倒着匹配，当我们发现某个字符没法匹配的时候。我们把这个没有匹配的字符叫作坏字符（主串中的字符）

![220daef736418df84367215647bca5da](img\220daef736418df84367215647bca5da.jpg)

当发生不匹配的时候，我们把坏字符对应的模式串中的字符下标记作 si。如果坏字符在模式串中存在，我们把这个坏字符在模式串中的下标记作 xi。如果不存在，我们把 xi 记作 -1。那模式串往后移动的位数就等于 si-xi。**（注意，我这里说的下标，都是字符在模式串的下标）**

如果坏字符在模式串里多处出现，那我们在计算 xi 的时候，选择最靠后的那个，因为这样不会让模式串滑动过多，导致本来可能匹配的情况被滑动略过

#### 【2】好后缀规则

![d78990dbcb794d1aa2cf4a3c646ae58a](img\d78990dbcb794d1aa2cf4a3c646ae58a.jpg)



我们把已经匹配的 bc 叫作好后缀，记作{u}。我们拿它在模式串中查找，如果找到了另一个跟{u}相匹配的子串{u*}，那我们就将模式串滑动到子串{u*}与主串中{u}对齐的位置

![b9785be3e91e34bbc23961f67c234b63](img\b9785be3e91e34bbc23961f67c234b63.jpg)



如果在模式串中找不到另一个等于{u}的子串，还要考察好后缀的后缀子串，是否存在跟模式串的前缀子串匹配的。

**从好后缀的后缀子串中，找一个最长的并且能跟模式串的前缀子串匹配的**，假设是{v}，然后将模式串滑动到如图所示的位置。

![6caa0f61387fd2b3109fe03d803192f9](img\6caa0f61387fd2b3109fe03d803192f9.jpg)

如何选择用好后缀规则还是坏字符规则，来计算模式串往后滑动的位数？我们可以**分别计算好后缀和坏字符往后滑动的位数，然后取两个数中最大的，作为模式串往后滑动的位数**。这种处理方法还可以避免我们前面提到的，根据坏字符规则，计算得到的往后滑动的位数，有可能是负数的情况。

#### 【3】实现

坏字符规则”本身不难理解。当遇到坏字符时，要计算往后移动的位数 si-xi，其中 xi 的计算是重点，我们如何求得 xi 呢？或者说，如何查找坏字符在模式串中出现的位置呢？

将模式串中的每个字符及其下标都存到散列表中。这样就可以快速找到坏字符在模式串的位置下标了。关于这个散列表，我们只实现一种最简单的情况，假设字符串的字符集不是很大，每个字符长度是 1 字节，我们用大小为 256 的数组，来记录每个字符在模式串中出现的位置。数组的下标对应字符的 ASCII 码值，数组中存储这个字符在模式串中出现的位置。

```

private static final int SIZE = 256; // 全局变量或成员变量
private void generateBC(char[] b, int m, int[] bc) {
  for (int i = 0; i < SIZE; ++i) {
    bc[i] = -1; // 初始化bc
  }
  for (int i = 0; i < m; ++i) {
    int ascii = (int)b[i]; // 计算b[i]的ASCII值
    bc[ascii] = i;
  }
}
```



### （4）KMP

KMP是一个解决模式串在文本串是否出现过，如果出现过，最早出现的位置的经典算法
Knuth-Morris-Pratt 字符串查找算法，简称为 “KMP算法”，常用于在一个文本串S内查找一个模式串P 的出现位置，KMP方法算法就利用之前判断过信息，通过一个next数组，保存模式串中前后最长公共子序列的长度，每次回溯时，通过next数组找到，前面匹配过的位置，省去了大量的计算时间
参考资料：https://www.cnblogs.com/ZuoAndFutureGirl/p/9028287.html

为什么JDK中String类的indexof不使用KMP或者Boyer-Moore等时间复杂度低的算法？

原来JDK的编写者们认为大多数情况下，字符串都不长，使用原始实现可能代价更低。因为KMP和Boyer-Moore算法都需要预先计算处理来获得辅助数组，需要一定的时间和空间，这可能在短字符串查找中相比较原始实现耗费更大的代价。而且一般大字符串查找时，程序员们也会使用其它特定的数据结构，查找起来更简单。这有点类似于排除特定情况下的快速排序了。不同环境选择不同算法。

#### 【1】next数组

**字符串的前缀**： 从下标0开始的一段连续的子串。”aba” 是”abaca”的一个前缀（prefix）。我们用prefix(i) 表示字符串中0~i这个前缀。

**字符串的后缀**：从任意下标开始到字符串结尾的一段连续子串。”aca“是“abaca”的一个后缀（suffix）。我们用suffix(i) 表示字符串中i~n-1 这段后缀。

**两个串的最长公共前缀**：两个串的前缀中相等且最长的一组前缀。“aba”是“abacc”和“ababb”的最长公共前缀。

[1]部分匹配值表

![QQ截图20200802144244](img\QQ截图20200802144244.png)



![QQ截图20200802144436](img\QQ截图20200802144436.png)



**其实就是把子串B当成主串，子串A当成模式串，发现子串B的‘C’不匹配，就把子串A取next[b]的值，和kmp中赋值的部分匹配表一样**

**把A当成主串，B是模式串也可以，但是此时子串B的部分匹配表就不是12345了，因为他已经失去了前边的字符串，他的部分匹配表就变成了子串A的部分匹配表00012**

#### 【2】kmp

![搜狗截图20年08月01日2116_2](img\搜狗截图20年08月01日2116_2.png)



![搜狗截图20年08月01日2117_3](img\搜狗截图20年08月01日2117_3.png)

### （5）sunday算法



![1111151-de12afd6cf6e4ffa.webp](img\1111151-de12afd6cf6e4ffa.webp.jpg)

上图的查找中，在haystack[1]和needle[1]的位置发生失配，接下来要做的事情，就是把needle右移。在右移之前我们先把注意力haystack[3]=d这个位置上。如果needle右移一位，needle[2]=c跟haystack[3]对应，如果右移两位，needle[1]=b跟haystack[3]对应，如果移三位，needle[0]=a跟haystack[3]对应。然后无论以上情况中的哪一种，在haystack[3]这个位置上都会失配(当然在这个位置前面也可能失配)，因为haystack[3]=d这个字母根本就不存在于needle中。因此更明智的做法应该是直接移四位，变成这样：

![1111151-5a860179346d8fec.webp](img\1111151-5a860179346d8fec.webp.jpg)

然后我们发现在needle[0]=a，haystack[4]=b位置又失配了，于是沿用上一步的思路，看看haystack[7]=b。这次我们发现字母b是在needle中存在的，那它就有可能形成一个完整的匹配，因为我们完全直接跳过，而应该跳到haystack[7]与needle[1]对应的位置，如下图：

![1111151-99ff943671f8d772.webp](img\1111151-99ff943671f8d772.webp.jpg)

![1111151-2512cede0727ed98.webp](img\1111151-2512cede0727ed98.webp.jpg)

```
输入: haystack, needle
Init: i=0, j=0
while i<=len(haystack)-len(needle):
    j=0
    						//这里i不动，j增加，也就是i+j在增加，那么如果找到，就是匹配的下标
    while j<len(needle) and haystack[i+j] equals needle[j]:
        j=j+1
    if j equals len(needle):
        return i
    else
        increase i...
```

发生失配时，i应该增加多少？

如果haystack[i+len(needle)]位置的字母不存在于needle中，我们知道可以跳到i+len(needle)+1的位置。而如果chr=haystack[i+len(needle)]存在于needle，我们说可以跳到使chr对应needle中的同一个字母的位置。但问题是，needle中可能有不止一个的字母等于chr。这种情况下，应该跳到哪一个位置呢？为了不遗漏可能的匹配，应该是跳到使得needle中最右一个chr与haystack[i+len(needle)]对应，这样跳过的距离最小，且是安全的。



于是把模式串向右移动3位（m - 3 = 6 - 3 = r 到模式串末尾的距离 + 1 = 2 + 1 =3），使两个’r’对齐，如下：

![20160708122414877](img\20160708122414877.jpg)

于是在开始查找之前，应该预处理needle，收集字母在needle中最右一次出现的位置。这时可以用数组，但是用哈希表更好，遍历needle，更新对应字母的位置，如果一个字母出现了两次，前一个位置就会被后一个覆盖，另外我们用-1表示根本不在needle中出现。



### （6）Trie 树（字典树）

一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。

Trie 树比较适合的是查找前缀匹配的字符串

Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起

Trie 树是非常耗内存的，用的是一种空间换时间的思路

#### 【1】特点

第一，根结点不包含字符；

第二，除根结点外每一个结点都只包含一个字符；

第三，从根结点到某一叶子结点，路径上经过的字符连接起来，即为集合中的某个字符串。

![CgqCHl7nVuSASW8lAADCDPk2Zv0987](img\CgqCHl7nVuSASW8lAADCDPk2Zv0987.png)

#### 【2】实现

![f5a4a9cb7f0fe9dcfbf29eb1e5da6d35](img\f5a4a9cb7f0fe9dcfbf29eb1e5da6d35.jpg)

```java

public class Trie {
  private TrieNode root = new TrieNode('/'); // 存储无意义字符

  // 往Trie树中插入一个字符串
  public void insert(char[] text) {
    TrieNode p = root;
    for (int i = 0; i < text.length; ++i) {
      int index = text[i] - 'a';
      if (p.children[index] == null) {
        TrieNode newNode = new TrieNode(text[i]);
        p.children[index] = newNode;
      }
      p = p.children[index];
    }
    p.isEndingChar = true;
  }

  // 在Trie树中查找一个字符串
  public boolean find(char[] pattern) {
    TrieNode p = root;
    for (int i = 0; i < pattern.length; ++i) {
      int index = pattern[i] - 'a';
      if (p.children[index] == null) {
        return false; // 不存在pattern
      }
      p = p.children[index];
    }
    if (p.isEndingChar == false) return false; // 不能完全匹配，只是前缀
    else return true; // 找到pattern
  }

  public class TrieNode {
    public char data;
    public TrieNode[] children = new TrieNode[26];
    public boolean isEndingChar = false;
    public TrieNode(char data) {
      this.data = data;
    }
  }
}
```



#### 【3】应用场景

[1]输入一个字符串，判断它在已有的字符串集合中是否出现过?（假设集合中没有某个字符串与另一个字符串拥有共同前缀且完全包含的特殊情况，例如 deep 和 dee。）

这个问题的解法可以拆解为以下两个步骤：

第一步，根据候选字符串集合，建立字典树。这需要使用数据插入的动作。

第二步，对于一个输入字符串，判断它能否在这个树结构中走到叶子结点。如果能，则出现过。

[2]搜索引擎的搜索关键词提示功能

![ceb8738453401d5fc067acd513b57a9e](img\ceb8738453401d5fc067acd513b57a9e.png)

### （7）AC自动机

#### 【1】应用场景

用多模式串匹配实现敏感词过滤功能

#### 【2】多模式串匹配算法

在多个模式串和一个主串之间做匹配，也就是说，在一个主串中查找多个模式串

AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了



## 9、最小生成树MST

给定一个带权的无向连通图,如何选取一棵生成树,使树上所有边上权的总和为最小,这叫最小生成树 
N个顶点，一定有N-1条边;包含全部顶点;N-1条边都在图中



![微信截图_20200808190304](img\微信截图_20200808190304.png)



有7个村庄(A, B, C, D, E, F, G) ，现在需要修路把7个村庄连通
各个村庄的距离用边线表示(权) ，比如 A – B 距离 5公里
问：如何修路保证各个村庄都能连通，并且总的修建公路总里程最短?
思路: 尽可能的选择少的路线，并且每条路线最小，保证总里程数最少.



### （1）普里姆算法（贪心）对点操作

【1】设G=(V,E)是连通网，T=(U,D)是最小生成树，V,U是顶点集合，E,D是边的集合 
【2】若从顶点u开始构造最小生成树，则从集合V中取出顶点u放入集合U中，标记顶点v的visited[u]=1
【3】若集合U中顶点ui与集合V-U中的顶点vj之间存在边，则寻找这些边中权值最小的边，但不能构成回路，将顶点vj加入集合U中，将边（ui,vj）加入集合D中，标记visited[vj]=1
【4】重复步骤【2】，直到U与V相等，即所有顶点都被标记为访问过



```
1.从<A>顶点开始处理  ======> <A,G> 2
A-C [7] A-G[2] A-B[5] => 

2. <A,G> 开始 , 将A 和 G 顶点和他们相邻的还没有访问的顶点进行处理 =》<A,G,B>
A-C[7] A-B[5]  G-B[3] G-E[4] G-F[6]

3. <A,G,B> 开始，将A,G,B 顶点 和他们相邻的还没有访问的顶点进行处理=><A,G,B,E>
A-C[7] G-E[4] G-F[6] B-D[9] 
.....
4.{A,G,B,E}->F//第4次大循环 ，  对应 边<E,F> 权值：5
5.{A,G,B,E,F}->D//第5次大循环 ， 对应 边<F,D> 权值：4
6. {A,G,B,E,F,D}->C//第6次大循环 ， 对应 边<A,C> 权值：7 ===> <A,G,B,E,F,D,C>

```



### （2）克鲁斯卡尔算法（对边操作）

基本思想：按照权值从小到大的顺序选择n-1条边，并保证这n-1条边不构成回路
具体做法：首先构造一个只含n个顶点的森林，然后依权值从小到大从连通网中选择边加入到森林中，并使森林中不产生回路，直至森林变成一棵树为止



![QQ截图20200808230456](img\QQ截图20200808230456.png)

**不能按照节点是否访问过来判断有回路，否则，在连接了FE和CD两条边后，实际上DE已经都访问过了，如果按照这种情况，DE都这条边都无法连上**

```
克鲁斯卡尔算法重点需要解决的以下两个问题： 
问题一:对图的所有边按照权值大小进行排序。 
问题二:将边添加到最小生成树中时，怎么样判断是否形成了回路。

问题一很好解决，采用排序算法进行排序即可。

问题二，处理方式是：记录顶点在"最小生成树"中的终点，顶点的终点是"在最小生成树中与它连通的最大顶点"(*关于这一点，后面会通过图片给出说明*)。然后每次需要将一条边添加到最小生存树时，判断该边的两个顶点的终点是否重合，重合的话则会构成回路。 以下图来进行说明：

在将<E,F> <C,D> <D,E>加入到最小生成树R中之后，这几条边的顶点就都有了终点：

C的终点是F。 
D的终点是F。 
E的终点是F。 
F的终点是F

关于终点，就是将所有顶点按照从小到大的顺序排列好之后；某个顶点的终点就是"与它连通的最大顶点"。 因此，接下来，虽然<C,E>是权值最小的边。但是C和E的重点都是F，即它们的终点相同，因此，将<C,E>加入最小生成树的话，会形成回路。这就是判断回路的方式。
```

## 10、最短路径

### （1）迪杰斯特拉(Dijkstra)

O(E*logV)

单源到其他顶点的最短路径，BFS，动态规划

设置出发顶点为v，顶点集合V{v1,v2,vi...}，v到V中各顶点的距离构成距离集合Dis，Dis{d1,d2,di...}，Dis集合记录着v到图中各顶点的距离(到自身可以看作0，v到vi距离对应为di)
[1]从Dis中选择值最小的di并移出Dis集合，同时移出V集合中对应的顶点vi，此时的v到vi即为最短路径

[2]更新Dis集合，更新规则为：比较v到V集合中顶点的距离值，与v通过vi到V集合中顶点的距离值，保留值较小的一个(同时也应该更新顶点的前驱节点为vi，表明是通过vi到达的)
[3]重复执行两步骤，直到最短路径顶点为目标顶点即可结束

https://www.geeksforgeeks.org/dijkstras-shortest-path-algorithm-greedy-algo-7/

### （2）弗洛伊德(Floyd)

各个顶点到其余顶点之间的最短路径

[1]设置顶点vi到顶点vk的最短路径已知为Lik，顶点vk到vj的最短路径已知为Lkj，顶点vi到vj的路径为Lij，则vi到vj的最短路径为：min((Lik+Lkj),Lij)，vk的取值为图中所有顶点，则可获得vi到vj的最短路径
[2]至于vi到vk的最短路径Lik或者vk到vj的最短路径Lkj，是以同样的方式获得



![微信截图_20200814173639](img\微信截图_20200814173639.png)





### （3）A* 和 IDA* 



【1】A* 算法

找出一条接近于最短路线的次优路线

当我们遍历到某个顶点的时候，从起点走到这个顶点的路径长度是确定的，我们记作 g(i)（i 表示顶点编号）。但是，从这个顶点到终点的路径长度，我们是未知的。虽然确切的值无法提前知道，但是我们可以用其他估计值来代替。这里我们可以通过这个顶点跟终点之间的直线距离，也就是欧几里得距离，来近似地估计这个顶点跟终点的路径长度（注意：路径长度跟直线距离是两个概念）。我们把这个距离记作 h(i)（i 表示这个顶点的编号），专业的叫法是**启发函数**（heuristic function）。因为欧几里得距离的计算公式，会涉及比较耗时的开根号计算，所以，我们一般通过另外一个更加简单的距离计算公式，那就是**曼哈顿距离**（Manhattan distance）。曼哈顿距离是两点之间横纵坐标的距离之和。

```java

int hManhattan(Vertex v1, Vertex v2) { // Vertex表示顶点，后面有定义
  return Math.abs(v1.x - v2.x) + Math.abs(v1.y - v2.y);
}
```

原来只是单纯地通过顶点与起点之间的路径长度 g(i)，来判断谁先出队列，现在有了顶点到终点的路径长度估计值，我们通过两者之和 **f(i)=g(i)+h(i)**，来判断哪个顶点该最先出队列。综合两部分，我们就能有效避免刚刚讲的“跑偏”。这里 f(i) 的专业叫法是**估价函数**

A* 算法跟 Dijkstra 算法的代码实现，主要有 3 点区别：

- 优先级队列构建的方式不同。A* 算法是根据 f 值（也就是刚刚讲到的 f(i)=g(i)+h(i)）来构建优先级队列，而 Dijkstra 算法是根据 dist 值（也就是刚刚讲到的 g(i)）来构建优先级队列；
- A* 算法在更新顶点 dist 值的时候，会同步更新 f 值；
- 循环结束的条件也不一样。Dijkstra 算法是在终点出队列的时候才结束，A* 算法是一旦遍历到终点就结束。

A* 算法利用贪心算法的思路，每次都找 f 值最小的顶点出队列，一旦搜索到终点就不在继续考察其他顶点和路线了。所以，它并没有考察所有的路线，也就不可能找出最短路径了。

https://blog.csdn.net/sslz_fsy/article/details/82154996

【2】应用

游戏中的寻路功能

把整个地图分割成一个一个的小方块。在某一个方块上的人物，只能往上下左右四个方向的方块上移动。我们可以把每个方块看作一个顶点。两个方块相邻，我们就在它们之间，连两条有向边，并且边的权值都是 1。所以，这个问题就转化成了，在一个有向有权图中，找某个顶点到另一个顶点的路径问题。将地图抽象成边权值为 1 的有向图之后，我们就可以套用 A* 算法，来实现游戏中人物的自动寻路功能了。

## 11、并查集

若某个家族人员过于庞大，要判断两个是否是亲戚，确实不容易，给出某个亲戚关系图，求任意给出的两个人是否具有亲戚关系。



## 12、图的拓扑排序

### （1）应用

拓扑排序应用非常广泛，解决的问题的模型也非常一致。凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。

【1】编译器通过分析源文件或者程序员事先写好的编译配置文件（比如 Makefile 文件），来获取这种局部的依赖关系。那编译器又该如何通过源文件两两之间的局部依赖关系，确定一个全局的编译顺序呢？

【2】除此之外，拓扑排序还能检测图中环的存在。对于 Kahn 算法来说，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环。

![5247b6639e98419a1963cecd8f12713b](img\5247b6639e98419a1963cecd8f12713b.jpg)

### （2）拓扑排序本身就是基于有向无环图的一个算法。

拓扑排序有两种实现方法，都不难理解。它们分别是 Kahn 算法和 DFS 深度优先搜索算法。

```java

public class Graph {
  private int v; // 顶点的个数
  private LinkedList<Integer> adj[]; // 邻接表

  public Graph(int v) {
    this.v = v;
    adj = new LinkedList[v];
    for (int i=0; i<v; ++i) {
      adj[i] = new LinkedList<>();
    }
  }

  public void addEdge(int s, int t) { // s先于t，边s->t
    adj[s].add(t);
  }
}
```



#### 【1】Kahn 算法

O(V+E)

Kahn 算法实际上用的是贪心算法思想，思路非常简单、好懂。定义数据结构的时候，如果 s 需要先于 t 执行，那就添加一条 s 指向 t 的边。所以，如果某个顶点入度为 0， 也就表示，没有任何顶点必须先于这个顶点执行，那么这个顶点就可以执行了。

我们先从图中，找出一个入度为 0 的顶点，将其输出到拓扑排序的结果序列中（对应代码中就是把它打印出来），并且把这个顶点从图中删除（也就是把这个顶点可达的顶点的入度都减 1）。我们循环执行上面的过程，直到所有的顶点都被输出。最后输出的序列，就是满足局部依赖关系的拓扑排序。

```java

public void topoSortByKahn() {
  int[] inDegree = new int[v]; // 统计每个顶点的入度
  for (int i = 0; i < v; ++i) {
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inDegree[w]++;
    }
  }
  LinkedList<Integer> queue = new LinkedList<>();
  for (int i = 0; i < v; ++i) {
    if (inDegree[i] == 0) queue.add(i);
  }
  while (!queue.isEmpty()) {
    int i = queue.remove();
    System.out.print("->" + i);
    for (int j = 0; j < adj[i].size(); ++j) {
      int k = adj[i].get(j);
      inDegree[k]--;
      if (inDegree[k] == 0) queue.add(k);
    }
  }
}
```

#### 【2】DFS

O(V+E)

第一部分是通过邻接表构造逆邻接表。邻接表中，边 s->t 表示 s 先于 t 执行，也就是 t 要依赖 s。在逆邻接表中，边 s->t 表示 s 依赖于 t，s 后于 t 执行

第二部分是这个算法的核心，也就是递归处理每个顶点。对于顶点 vertex 来说，我们先输出它可达的所有顶点，也就是说，先把它依赖的所有的顶点输出了，然后再输出自己。

```java

public void topoSortByDFS() {
  // 先构建逆邻接表，边s->t表示，s依赖于t，t先于s
  LinkedList<Integer> inverseAdj[] = new LinkedList[v];
  for (int i = 0; i < v; ++i) { // 申请空间
    inverseAdj[i] = new LinkedList<>();
  }
  for (int i = 0; i < v; ++i) { // 通过邻接表生成逆邻接表
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inverseAdj[w].add(i); // w->i
    }
  }
  boolean[] visited = new boolean[v];
  for (int i = 0; i < v; ++i) { // 深度优先遍历图
    if (visited[i] == false) {
      visited[i] = true;
      dfs(i, inverseAdj, visited);
    }
  }
}

private void dfs(
    int vertex, LinkedList<Integer> inverseAdj[], boolean[] visited) {
  for (int i = 0; i < inverseAdj[vertex].size(); ++i) {
    int w = inverseAdj[vertex].get(i);
    if (visited[w] == true) continue;
    visited[w] = true;
    dfs(w, inverseAdj, visited);
  } // 先把vertex这个顶点可达的所有顶点都打印出来之后，再打印它自己
  System.out.print("->" + vertex);
}
```

## 13、位图和布隆过滤器



```
将数字 A 的第 k 位设置为1：A = A | (1 << (k - 1))
将数字 A 的第 k 位设置为0：A = A & ~(1 << (k - 1))
检测数字 A 的第 k 位：A & (1 << (k - 1)) != 0
```



### （1）位图

有 1 千万个整数，整数的范围在 1 到 1 亿之间。如何快速查找某个整数是否在这 1 千万个整数中呢？

**特殊”的散列表，那就是位图。**

[Bitmap算法 整合版](https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg)



![微信截图_20200909150729](img\微信截图_20200909150729.png)

![微信截图_20200909151402](img\微信截图_20200909151402.png)



**意思是建立4个word，每个word都是long，是64位，每次插入一个值，按照以下的规则（类似）计算下标和值，然后把对应下标做处理，其实就是把word中的64位的对应的下标改成1，参考上边0到9，把对应的下标改成1**

```java
public void set(int k) {
		if (k > nbits)
			return;
		int byteIndex = k / 16;
		int bitIndex = k % 16;
		bytes[byteIndex] |= (1 << bitIndex);
	}
```



我们申请一个大小为 1 亿、数据类型为布尔类型（true 或者 false）的数组。我们将这 1 千万个整数作为数组下标，将对应的数组值设置成 true。比如，整数 5 对应下标为 5 的数组值设置为 true，也就是 array[5]=true。当我们查询某个整数 K 是否在这 1 千万个整数中的时候，我们只需要将对应的数组值 array[K]取出来，看是否等于 true。如果等于 true，那说明 1 千万整数中包含这个整数 K；相反，就表示不包含这个整数 K。

不过，很多语言中提供的布尔类型，大小是 1 个字节的，并不能节省太多内存空间。实际上，表示 true 和 false 两个值，我们只需要用一个二进制位（bit）就可以了。

```java

public class BitMap { // Java中char类型占16bit，也即是2个字节
  private char[] bytes;
  private int nbits;
  
  public BitMap(int nbits) {
    this.nbits = nbits;
    this.bytes = new char[nbits/16+1];
  }

  public void set(int k) {
    if (k > nbits) return;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    bytes[byteIndex] |= (1 << bitIndex);
  }

  public boolean get(int k) {
    if (k > nbits) return false;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    return (bytes[byteIndex] & (1 << bitIndex)) != 0;
  }
}
```

不过，这里我们有个假设，就是数字所在的范围不是很大。如果数字的范围很大，比如刚刚那个问题，数字范围不是 1 到 1 亿，而是 1 到 10 亿，那位图的大小就是 10 亿个二进制位，也就是 120MB 的大小，消耗的内存空间，不降反增。

这个时候，布隆过滤器就要出场了。布隆过滤器就是为了解决刚刚这个问题，对位图这种数据结构的一种改进。

### （2）布隆过滤器

**布隆过滤器非常适合这种不需要 100% 准确的、允许存在小概率误判的大规模判重场景。**

布隆过滤器使用 K 个哈希函数，对同一个数字进行求哈希值，那会得到 K 个不同的哈希值，我们分别记作 X1，X2，X3，…，XK。我们把这 K 个数字作为位图中的下标，将对应的 BitMap[X1]，BitMap[X2]，BitMap[X3]，…，BitMap[XK]都设置成 true，也就是说，我们用 K 个二进制位，来表示一个数字的存在。当我们要查询某个数字是否存在的时候，我们用同样的 K 个哈希函数，对这个数字求哈希值，分别得到 Y1，Y2，Y3，…，YK。我们看这 K 个哈希值，对应位图中的数值是否都为 true，如果都是 true，则说明，这个数字存在，如果有其中任意一个不为 true，那就说明这个数字不存在。



![94630c1c3b7657f560a1825bd9d02cae](img\94630c1c3b7657f560a1825bd9d02cae.jpg)

布隆过滤器的误判有一个特点，那就是，它只会对存在的情况有误判。**如果某个数字经过布隆过滤器判断不存在，那说明这个数字真的不存在，不会发生误判；如果某个数字经过布隆过滤器判断存在，这个时候才会有可能误判，有可能并不存在。**不过，只要我们调整哈希函数的个数、位图大小跟要存储数字的个数之间的比例，那就可以将这种误判的概率降到非常低。

### （3）应用

【1】网页爬虫中的URL去重功能？

我们用布隆过滤器来记录已经爬取过的网页链接，假设需要判重的网页有 10 亿，那我们可以用一个 10 倍大小的位图来存储，也就是 100 亿个二进制位，换算成字节，那就是大约 1.2GB。之前我们用散列表判重，需要至少 100GB 的空间。相比来讲，布隆过滤器在存储空间的消耗上，降低了非常多。那我们再来看下，利用布隆过滤器，在执行效率方面，是否比散列表更加高效呢？布隆过滤器用多个哈希函数对同一个网页链接进行处理，CPU 只需要将网页链接从内存中读取一次，进行多次哈希计算，理论上讲这组操作是 CPU 密集型的。而在散列表的处理方式中，需要读取散列值相同（散列冲突）的多个网页链接，分别跟待判重的网页链接，进行字符串匹配。这个操作涉及很多内存数据的读取，所以是内存密集型的。我们知道 CPU 计算可能是要比内存访问更快速的，所以，理论上讲，布隆过滤器的判重方式，更加快速。

【2】统计一个大型网站的每天的 UV 数，也就是每天有多少用户访问了网站，我们就可以使用布隆过滤器，对重复访问的用户进行去重。

## 14、朴素贝叶斯算法

（1）应用

垃圾短信过滤功能以及骚扰电话；

垃圾邮件的过滤

（2）基于黑名单的过滤器

如果黑名单中的电话号码不多的话，我们可以使用散列表、二叉树等动态数据结构来存储

布隆过滤器

（3）基于规则的过滤器

（4）基于概率统计的过滤器

![fbef6a760f916941bc3128c2d32540cc](img\fbef6a760f916941bc3128c2d32540cc.jpg)

（5）基于概率统计的过滤器，是基于短信内容来判定是否是垃圾短信

![b8f76a5fd26f785055b78ffe08ccfbe7](img\b8f76a5fd26f785055b78ffe08ccfbe7.jpg)



![39c57b1a8a008e50a9f6cb8b7b9c9bae](img\39c57b1a8a008e50a9f6cb8b7b9c9bae.jpg)



![6c261a3f5312c515cf348cc59a5e73f2](img\6c261a3f5312c515cf348cc59a5e73f2.jpg)

不过，P（W1，W2，W3，…，Wn 同时出现在一条短信中）这个概率还是不好通过样本统计得到，原因我们前面说过了，样本空间有限

我们可以分别计算同时包含 W1，W2，W3，…，Wn 这 n 个单词的短信，是垃圾短信和非垃圾短信的概率。假设它们分别是 p1 和 p2。我们并不需要单纯地基于 p1 值的大小来判断是否是垃圾短信，而是通过对比 p1 和 p2 值的大小，来判断一条短信是否是垃圾短信。更细化一点讲，那就是，如果 p1 是 p2 的很多倍（比如 10 倍），我们才确信这条短信是垃圾短信。

![0f0369a955ee8d15bd7d7958829d5b2a](img\0f0369a955ee8d15bd7d7958829d5b2a.jpg)

## 15、推荐

- 找到跟你口味偏好相似的用户，把他们爱听的歌曲推荐给你；
- 找出跟你喜爱的歌曲特征相似的歌曲，把这些歌曲推荐给你。

### （1）基于相似用户做推荐

![056552502f1cf4fdf331488e0eed5fa9](img\056552502f1cf4fdf331488e0eed5fa9.jpg)

如何来判断两个用户是否口味相似呢？显然，我们不能再像之前那样，采用简单的计数来统计两个用户之间的相似度。还记得我们之前讲字符串相似度度量时，提到的编辑距离吗？这里的相似度度量，我们可以使用另外一个距离，那就是**欧几里得距离**（Euclidean distance）。

### （2）基于相似歌曲做推荐

对于两首歌，如果喜欢听的人群都是差不多的，那侧面就可以反映出，这两首歌比较相似。如图所示，每个用户对歌曲有不同的喜爱程度，我们依旧通过上一个解决方案中定义得分的标准，来定义喜爱程度。

![a324908e162a60efea4bd7c47c04a6ff](img\a324908e162a60efea4bd7c47c04a6ff.jpg)

**这个图跟基于相似用户推荐中的图几乎一样。只不过这里把歌曲和用户主次颠倒了一下。基于相似用户的推荐方法中，针对每个用户，我们将对各个歌曲的喜爱程度作为向量。基于相似歌曲的推荐思路中，针对每个歌曲，我们将每个用户的打分作为向量。**

（3）推荐系统（Recommender System）是典型的机器学习应用场景。其核心就是通过算法得到用户偏好向量以及内容向量，两个向量的内积即为用户对内容的的评分预测（即用户对某内容的喜好程度）。推荐学习算法本质上就是学习这两个向量的过程。
通常有两种方法：
【1】已知内容向量，学习用户偏好向量的方法就是基于内容的推荐算法（content-based）；
【2】用户偏好向量和内容向量都未知，则适合使用联合过滤算法（collaborative filtering）同时学习两个向量。