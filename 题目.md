# 零、时间复杂度

| 复杂度   | 可能对应的语法                                               | 备注                           |
| -------- | ------------------------------------------------------------ | ------------------------------ |
| O(1)     | 位运算                                                       | 常数级复杂度，一般面试中不会有 |
| O(logn)  | 二分法，倍增法，快速幂算法，辗转相除法                       |                                |
| O(n)     | 双指针算法，单调栈算法，枚举法(for循环)，KMP算法，Rabin Karp，Manacher's Algorithm | 又称作线性时间复杂度           |
| O(nlogn) | 快速排序，归并排序，堆排序，O(n* logn)的数据结构上的操作     |                                |
| O(n^2)   | 枚举法，动态规划，Dijkstra                                   |                                |
| O(n^3)   | 枚举法，动态规划，Floyd                                      |                                |
| O(2^n)   | 与组合有关的搜索问题                                         |                                |
| O(n!)    | 与排列有关的搜索问题                                         |                                |



O(n* logn)的数据结构上的操作：平衡BST的增删查、heap、跳表、线段树

计算数量的问题，如果可以用数学公式一次性加多个，比一个个加，就降低了复杂度

## 1、O(N)的算法

### （1）双指针算法

![微信截图_20201013210310](img\微信截图_20201013210310.png)

#### 【1】相向双指针

[1]Two Sum

[2]partiton类型：分割数组

快速排序、颜色排序

[3]Reverse类型：

判断回文串（背向双指针也能做）、反转字符串

#### 【2】背向双指针

最长回文串（中心线枚举）、find k closest 元素、平方后排序

find k closest 元素、平方后排序很像归并排序

#### 【3】同向双指针

![搜狗截图20年11月15日2003_1](img\搜狗截图20年11月15日2003_1.png)

list中的环

### （2）打擂台算法

在循环里跟一个值比较

### （3）单调栈算法、单调队列算法

## 2、低于O(N)的算法

（1）快速幂算法O(logn)

![QQ截图20201008165816](img\QQ截图20201008165816.png)

（2）辗转相除法O(logn)

又名欧几里德算法， 是求最大公约数的一种方法。它的具体做法是：用**较大的数**除以**较小的数**，再用**除数**除以出现的**余数**（第一余数），再用**第一余数**除以出现的**余数**（第二余数），如此反复，直到最后余数是0为止。如果是求两个数的最大公约数，那么最后的除数就是这两个数的最大公约数。



```java
public int gcd(int big, int small) {
    if (small != 0) {
        return gcd(small, big % small);
    } else {
        return big;
    }
}
```



（3）分解质因数O(sqrt(n))
$$
O(√N)
$$


【1】具体步骤

1. 记up = sqrt{n}，作为质因数k的上界, 初始化k=2。
2. 当k <= up 且 n不为1 时，执行步骤3，否则执行步骤4。
3. 当n被k整除时，不断整除并覆盖n，同时结果中记录k，直到n不能整出k为止。之后k自增，执行步骤2。
4. 当n不为1时，把n也加入结果当中，算法结束。

【2】几点解释

- 不需要判定k是否为质数，如果k不为质数，且能整出n时，n早被k的因数所除。故能整除n的k必是质数。
- 为何引入up？为了优化性能。当k大于up时，k已不可能整除n，除非k是n自身。也即为何步骤4判断n是否为1，n不为1时必是比up大的质数。
- 步骤2中，也判定n是否为1，这也是为了性能，当n已为1时，可早停。

【3】复杂度分析

- 最坏时间复杂度O(sqrt (n) )。当n为质数时，取到其最坏时间复杂度。
- 空间复杂度O(log(n)), 当n质因数很多时，需要空间大，但总不会多于O(log(n))个

```Java
public List<Integer> primeFactorization(int n) {
    List<Integer> result = new ArrayList<>();
    int up = (int) Math.sqrt(n);
    
    for (int k = 2; k <= up && n > 1; ++k) {
        while (n % k == 0) {
            n /= k;
            result.add(k);
        }
    }
    
    if (n > 1) {
        result.add(n);
    }
    
    return result;
}
```

（4）分块检索法，可能最优解是O(logn)
$$
O(√N)
$$

将长度为N的**区间**分成sqrt(N)的大小的区间，总共sqrt(N)个区间，每个小区间统计局部的数据
因此在这些区间中进行增删改查的效率是O(sqrt(N))

**其实就是分治法中的分和bitmap中分块的思想**，在O(1)的时间复杂度内找到这个小区间，在小区间内用遍历查找

【1】应用

lintcode 249 统计数组中前面比自己小的数的个数

由于给定的数组有范围 0 到10000，所以可以将10000的区间按照sqrt(N)的大小划分为101个区间（block），对于数组中的每个数模101即可以得到对应的block，同时对于每个block维护一个total的变量，记录每个block中的数量，当要求某个数前面有多少个数的时候，可以将前边total加起来，再对该数所在的block进行遍历

## 3、常用数据结构接口

![360截图20201206210259106](img\360截图20201206210259106.jpg)

HashMap和HashSet的区别？

首先得看java最基本的两种数据结构：数组和链表的区别：

数组易于快速读取（通过for循环），不便存储（数组长度有限制）；链表易于存储，不易于快速读取。

**哈希表的出现是为了解决链表访问不快速的弱点，哈希表也称散列表**。

HashSet是通过HashMap来实现的，HashMap的输入参数有Key、Value两个组成，在实现HashSet的时候，保持HashMap的Value为常量，相当于在HashMap中只对Key对象进行处理。

HashMap的底层是一个数组结构，数组中的每一项对应了一个链表，这种结构称“链表散列”的数据结构，即数组和链表的结合体；也叫散列表、哈希表。

**一、HashMap存储对象的过程**

1、对HashMap的Key调用hashCode()方法，返回int值，即对应的hashCode；

2、把此hashCode作为哈希表的索引，查找哈希表的相应位置，若当前位置内容为NULL，则把HashMap的Key、Value包装成Entry数组，放入当前位置；

3、若当前位置内容不为空，则继续查找当前索引处存放的链表，利用equals方法，找到Key相同的Entry数组，则用当前Value去替换旧的Value；

4、若未找到与当前Key值相同的对象，则把当前位置的链表后移（Entry数组持有一个指向下一个元素的引用），把新的Entry数组放到链表表头；

**二、HashSet存储对象的过程**

往HashSet添加元素的时候，HashSet会先调用元素的hashCode方法得到元素的哈希值 ，

然后通过元素 的哈希值经过移位等运算，就可以算出该元素在哈希表中 的存储位置。

情况1： 如果算出元素存储的位置目前没有任何元素存储，那么该元素可以直接存储到该位置上。

情况2： 如果算出该元素的存储位置目前已经存在有其他的元素了，那么会调用该元素的equals方法与该位置的元素再比较一次

，如果equals返回的是true，那么该元素与这个位置上的元素就视为重复元素，不允许添加，如果equals方法返回的是false，那么该元素运行添加。

**答案总结：HashSet和HashMap的区别**

| HashMap                          | HashSet                                                      |
| -------------------------------- | ------------------------------------------------------------ |
| 实现了Map接口                    | 实现Set接口                                                  |
| 存储键值对                       | 仅存储对象                                                   |
| 调用put（）向map中添加元素       | 调用add（）方法向Set中添加元素                               |
| HashMap使用键（Key）计算Hashcode | HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false |

HashSet实现了Set接口，其内部不允许出现重复的值，如果我们将一个对象存入HashSet，必须重写equals()和hashCode()方法，这样才能确保集合中不存在同一个元素。HashSet的内部是无序的，因此不能使用 hashset.get(index) 来获取元素。
HashMap实现了Map接口，其内容是键值对的映射（key->value），不允许出现相同的键（key）。在查询的时候会根据给出的键来查询对应的值。
我们可以认为，HashSet和HashMap增查操作的时间复杂度都是常数级的。

### （1）Set

Set注重独一无二,该体系集合可以知道某物是否已经存在于集合中,不会存储重复的元素。

| HashSet      | TreeSet(平衡BST) |
| ------------ | ---------------- |
| 无重复数据   | 无重复数据       |
| 可以有空数据 | 不能有空数据     |
| 数据无序     | 数据有序         |

### （2）Map

| HashMap                    | TreeMap(平衡BST)                                             |
| -------------------------- | ------------------------------------------------------------ |
| key 无重复，value 允许重复 | key 无重复，value 允许重复                                   |
| 允许 key 和 value 为空     | 不允许有null                                                 |
| 数据无序                   | 有序(存入元素的时候对元素进行自动排序，迭代输出的时候就按排序顺序输出) |

### （3）List

一个 List 是一个元素有序的、可以重复(这一点与Set和Map不同)、可以为 null 的集合，List的实现类在面试中常用是：**LinkedList** 和 **ArrayList**

- LinkedList
  - 基于链表实现
- ArrayList
  - 基于动态数组实现
- LinkedList 与 ArrayList 对比：
  - 对于随机访问get和set，ArrayList绝对优于LinkedList，因为LinkedList要移动指针
  - 对于新增和删除操作add和remove，在已经得到了需要新增和删除的元素位置的前提下，LinkedList可以在O(1)的时间内删除和增加元素，而ArrayList需要移动`增加或删除元素之后的所有元素`的位置，时间复杂度是O(n)的，因此LinkedList优势较大

### （4）Queue

队列是一种比较重要的数据结构，它支持FIFO(First in First out)，即尾部添加、头部删除（先进队列的元素先出队列），跟我们生活中的排队类似。

- PriorityQueue
  - 基于堆(heap)实现
  - 非FIFO(最先出队列的是优先级最高的元素)
- 普通 Queue
  - 基于链表实现
  - FIFO

## 4、数据结构设计类题目

通常需要自定义或者使用现成的数据结构来实现**动态**处理数据

# 一、数组

1、leetcode [41. 缺失的第一个正数](https://leetcode-cn.com/problems/first-missing-positive/)

给你一个未排序的整数数组，请你找出其中没有出现的最小的正整数。

```
示例 1:
输入: [1,2,0]
输出: 3

示例 2:
输入: [3,4,-1,1]
输出: 2

示例 3:
输入: [7,8,9,11,12]
输出: 1

```

把每个元素存放到对应的位置，比如1存放到数组的第一个位置，3存放到数组的第3个位置，
如果是非正数或者大于数组的长度的值，我们不做处理，最后在遍历一遍数组，如果位置不正确，说明这个位置没有这个数，我们就直接返回



![c21399184919c59c38cb34f180d2d729eca6219117cceef3f00e77427df7cd5d-image](img\c21399184919c59c38cb34f180d2d729eca6219117cceef3f00e77427df7cd5d-image.png)



![6fd89f64a49743c5d9234fc4fc8822b226bb1c003bc5acf465e702f648f05270-image](img\6fd89f64a49743c5d9234fc4fc8822b226bb1c003bc5acf465e702f648f05270-image.png)

![ea566e34cd0e41162e70121d955289ab3bf0398fb8945fecc9fe0915a9725cc7-image](img\ea566e34cd0e41162e70121d955289ab3bf0398fb8945fecc9fe0915a9725cc7-image.png)

作者：sdwwld
链接：https://leetcode-cn.com/problems/first-missing-positive/solution/javade-6chong-jie-fa-de-tu-wen-xiang-jie-wei-yun-s/
来源：力扣（LeetCode）
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

# 二、链表

## 1、技巧

（1）理解指针或引用的含义

将某个变量赋值给指针，实际上就是**将这个变量的地址赋值给指针**，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。

```
p->next=p->next->next
p 结点的 next 指针存储了 p 结点的下下一个结点的内存地址
```

（2）警惕指针丢失和内存泄漏

（3）利用哨兵简化实现难度

针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。

head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。**不直接参与业务逻辑。**

（4）重点留意边界条件处理

如果链表为空时，代码是否能正常工作？

如果链表只包含一个结点时，代码是否能正常工作？

如果链表只包含两个结点时，代码是否能正常工作？

代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

（5）举例画图，辅助思考

# 三、栈

## 1、单调栈

下一个更大的元素

![1598145577-ziwCvD-1](img\1598145577-ziwCvD-1.png)



# 四、散列表（哈希）

## 1、LeetCode [36. 有效的数独](https://leetcode-cn.com/problems/valid-sudoku/)

- 如何枚举子数独？

可以使用 `box_index = (row / 3) * 3 + columns / 3`，其中 `/` 是整数除法。

![2b141392e2a1811d0e8dfdf6279b1352e59fad0b3961908c6ff9412b6a7e7ccf-image](img\2b141392e2a1811d0e8dfdf6279b1352e59fad0b3961908c6ff9412b6a7e7ccf-image.png)



## 2、前缀和



![微信图片_20201208161202](img\微信图片_20201208161202.jpg)

### （1）什么是前缀和

前缀和的思路是这样的，对于一个给定的数组`nums`，我们额外开辟一个前缀和数组进行预处理：

```java
int n = nums.length;
// 前缀和数组
int[] preSum = new int[n + 1];
preSum[0] = 0;
for (int i = 0; i < n; i++)  
	preSum[i + 1] = preSum[i] + nums[i];
```

![微信截图_20201208161513](img\微信截图_20201208161513.png)



这个前缀和数组`preSum`的含义也很好理解，`preSum[i]`就是`nums[0..i-1]`的和。那么如果我们想求`nums[i..j]`的和，只需要一步操作`preSum[j+1]-preSum[i]`即可，

```java
int subarraySum(int[] nums, int k) {
    int n = nums.length;
    // 构造前缀和
    int[] sum = new int[n + 1];
    sum[0] = 0; 
    for (int i = 0; i < n; i++)
        sum[i + 1] = sum[i] + nums[i];

    int ans = 0;
    // 穷举所有子数组
    for (int i = 1; i <= n; i++)
        for (int j = 0; j < i; j++)
            // sum of nums[j..i-1]
            if (sum[i] - sum[j] == k)
                ans++;

    return ans;
}
```

### （2）优化

我们可以把 if 语句里的条件判断移项，这样写：

```
if (sum[j] == sum[i] - k)
    ans++;
```

优化的思路是：**我直接记录下有几个`sum[j]`和`sum[i]-k`相等，直接更新结果，就避免了内层的 for 循环**。

![微信截图_20201208161817](img\微信截图_20201208161817.png)

### （3）总结

前缀和不难，却很有用，主要用于处理数组区间的问题。

比如说，让你统计班上同学考试成绩在不同分数段的百分比，也可以利用前缀和技巧：

给你任何一个分数段，你都能通过前缀和相减快速计算出这个分数段的人数，百分比也就很容易计算了。

# 五、堆

**堆是实现优先队列的一种数据结构，不是优先队列是实现堆的数据结构**

1、堆vs优先队列

优先队列是一种抽象的数据类型，它和堆的关系类似于，List和数组、链表的关系一样；我们常常使用堆来实现优先队列，因此很多时候堆和优先队列都很相似，它们只是概念上的区分。
优先队列的应用场景十分的广泛，常见的应用有：

- Dijkstra’s algorithm（单源最短路问题中需要在邻接表中找到某一点的最短邻接边，这可以将复杂度降低。）
- Huffman coding（贪心算法的一个典型例子，采用优先队列构建最优的前缀编码树(prefixEncodeTree)）
- Prim’s algorithm for minimum spanning tree

在java，python中都已经有封装了的Priority Queue(Heaps)
优先队列是一个至少能够提供插入（Insert）和删除最小（DeleteMin）这两种操作的数据结构。对应于队列的操作，Insert相当于Enqueue，DeleteMin相当于Dequeue。
用堆实现优先的过程中，需要注意最大堆只能对应最大优先队列，最小堆则是对应最小优先队列。

1、堆化

对于每个元素A[i]，比较A[i]和它的父亲结点的大小，如果小于父亲结点，则与父亲结点交换。
交换后再和新的父亲比较，重复上述操作，直至该点的值大于父亲。
时间复杂度分析：
对于每个元素都要遍历一遍，这部分是 O(n)
每处理一个元素时，最多需要向根部方向交换 logn次。
因此总的时间复杂度是 O(nlogn)

```java
public class Solution {
    /**
     * @param A: Given an integer array
     * @return: void
     */
    private void siftup(int[] A, int k) {
        while (k != 0) {
            int father = (k - 1) / 2;
            if (A[k] > A[father]) {
                break;
            }
            int temp = A[k];
            A[k] = A[father];
            A[father] = temp;
            
            k = father;
        }
    }
    
    public void heapify(int[] A) {
        for (int i = 0; i < A.length; i++) {
            siftup(A, i);
        }
    }
}
```

除了上面的代码，我们也可以使用更有效率的O(n)的算法。
基于 Siftdown 的版本 O(n)

初始选择最接近叶子的一个父结点，与其两个儿子中较小的一个比较，若大于儿子，则与儿子交换。
交换后再与新的儿子比较并交换，直至没有儿子。
再选择较浅深度的父亲结点，重复上述步骤。
时间复杂度分析
这个版本的算法，乍一看也是 O(nlogn)， 但是我们仔细分析一下，算法从第 n/2 个数开始，倒过来进行 siftdown。也就是说，相当于从 heap 的倒数第二层开始进行 siftdown 操作，倒数第二层的节点大约有 n/4 个， 这 n/4 个数，最多 siftdown 1次就到底了，所以这一层的时间复杂度耗费是 O(n/4)，然后倒数第三层差不多 n/8 个点，最多 siftdown 2次就到底了。所以这里的耗费是 O(n/8 * 2), 倒数第4层是 O(n/16 * 3)，倒数第5层是 O(n/32 * 4) ... 因此累加所有的时间复杂度耗费为：
T(n) = O(n/4) + O(n/8 * 2) + O(n/16 * 3) ...
然后我们用 2T - T 得到：
2 * T(n) = O(n/2) + O(n/4 * 2) + O(n/8 * 3) + O(n/16 * 4) ...
T(n) = O(n/4) + O(n/8 * 2) + O(n/16 * 3) ...

2 * T(n) - T(n) = O(n/2) +O (n/4) + O(n/8) + ...
= O(n/2 + n/4 + n/8 + ... )
= O(n)
因此得到 T(n) = 2 * T(n) - T(n) = O(n)

```java
public class Solution {
    /**
     * @param A: Given an integer array
     * @return: void
     */
    private void siftdown(int[] A, int k) {
        while (k * 2 + 1 < A.length) {
            int son = k * 2 + 1;   // A[i] 的左儿子下标。
            if (k * 2 + 2 < A.length && A[son] > A[k * 2 + 2])
                son = k * 2 + 2;     // 选择两个儿子中较小的。
            if (A[son] >= A[k])      
                break;
            
            int temp = A[son];
            A[son] = A[k];
            A[k] = temp;
            k = son;
        }
    }
    
    public void heapify(int[] A) {
        for (int i = (A.length - 1) / 2; i >= 0; i--) {
            siftdown(A, i);
        }
    }
}
```

3、堆排序

运用堆的性质，我们可以得到一种常用的、稳定的、高效的排序算法————堆排序。堆排序的时间复杂度为O(n*log(n))，空间复杂度为O(1)，堆排序的思想是：对于含有n个元素的无序数组nums, 构建一个堆(这里是小顶堆)heap，然后执行extractMin得到最小的元素，这样执行n次得到序列就是排序好的序列。
如果是降序排列则是小顶堆；否则利用大顶堆。

Trick

由于extractMin执行完毕后，最后一个元素last已经被移动到了root，因此可以将extractMin返回的元素放置于最后，这样可以得到sort in place的堆排序算法。
当然，如果不使用前面定义的heap，则可以手动写堆排序，由于堆排序设计到建堆和extractMin， 两个操作都公共依赖于siftDown函数，因此我们只需要实现siftDown即可。(trick:由于建堆操作可以采用siftUp或者siftDown，而extractMin是需要siftDown操作，因此取公共部分，则采用siftDown建堆)。

升序堆排序（JAVA）

```java
public class Solution {
    private void siftdown(int[] A, int left, int right) {
        int k = left;
        while (k * 2 + 1 <= right) {
            int son = k * 2 + 1;
            if (son + 1 <= right && A[son] < A[son + 1]) {
                son = k * 2 + 2;
            }
            if (A[son] <= A[k]) {
                break;
            }
            int tmp = A[son];
            A[son] = A[k];
            A[k] = tmp;
            k = son;
        }
    }
    
    public void heapify(int[] A) {
        for (int i = (A.length - 1) / 2; i >= 0; i--) {
            siftdown(A, i, A.length - 1);
        }
    }
    
    void sortIntegers(int[] A) {
        heapify(A);
        for (int i = A.length - 1; i > 0; i--) {
            int tmp = A[0];
            A[0] = A[i];
            A[i] = tmp;
            siftdown(A, 0, i - 1);
        }
    }
}
```



# 六、图



# 七、字符串

## 1、字符串的子串的个数

字串：串中任意个**连续的字符**组成的子序列称为该串的字串，所以不能用组合数进行计算

​    空串属于字串

（1）长度为n的字符串，如果串中字符各不相同，则字串的个数为n(n+1)/2+1

解析：

- 包含1个字符的子串共n个
- 包含2个字符的子串共n-1个
- 包含3个字符的子串共n-2个
- 包含4个字符的子串共n-3个
- .。。。。。
- 包含n个字符的子串共1个
- 空串1个
- 综上所述：子串个数共：1+2+3+。。。+n+1（空串）=n(n+1)/2+1

（2）串中字符出现重复：字符串[www.qq.com](http://www.qq.com/)所有非空子串（两个子串如果内容相同则只算一个）个数是（）

- 答案：50
- 备注：存在相同字符，所以计算方法为总个数减去重复个数，即n(n+1)/2+1-重复个数
- 解析：包含重复子串共：n(n+1)/2+1=10（10+1）/2+1=55，减去重复：2个w，1个ww，1个q，1个.，所以共55-5=50个

（3）**假定空串不算子序列也不算子串, 那么一个长度为 N 的字符串最多有多少个不同的子序列和子串呢?**

2^n-1个子序列

# 八、字符串匹配

## 1、字典树

如何利用 Trie 树，实现搜索关键词的提示功能？

我们假设关键词库由用户的热门搜索关键词组成。我们将这个词库构建成一个 Trie 树。当用户输入其中某个单词的时候，把这个词作为一个前缀子串在 Trie 树中匹配。为了讲解方便，我们假设词库里只有 hello、her、hi、how、so、see 这 6 个关键词。当用户输入了字母 h 的时候，我们就把以 h 为前缀的 hello、her、hi、how 展示在搜索提示框内。当用户继续键入字母 e 的时候，我们就把以 he 为前缀的 hello、her 展示在搜索提示框内。这就是搜索关键词提示的最基本的算法原理。

![4ca9d9f78f2206cad93836a2b1d6d80d](img\4ca9d9f78f2206cad93836a2b1d6d80d.jpg)



# 九、BFS

**入队列的时候是不重复的，所以用set或者map，而岛屿问题是因为要传入(x,y)坐标，Java中二元组不好弄，所以用同样大小的boolean数组，或者将二维坐标转成一维坐标**

**Java 队列建议 new ArrayDeque 不建议 new LinkedList**

1、适用场景

![微信截图_20201118191016](img\微信截图_20201118191016.png)

（1）分层遍历

【1】一层一层的遍历一个图、树、矩阵

【2】简单图（图中所有的边长都一样）的**最短路径**，而且是最优的算法



**最长路径**
图可以分层：动态规划 Dynamic Programming
图不可以分层：深度优先搜索 DFS
分层的意思是：路径有一定方向性，不能绕圈
第i层的点只能走到第i+1层不能回到底 i-1 层



（2）连通块

【1】通过图中一个点找到其他所有连通的点

【2】找到所有方案问题的一种非递归实现方式

（3）拓扑排序

BFS比DFS容易实现，应用在先修课程、文件编译这种有依赖关系的图中

拓扑排序并不是传统的排序算法
一个图可能存在多个拓扑序（Topological Order），也可能不存在任何拓扑序

有拓扑排序说明是有向无环图，没有拓扑排序说明有环存在。但跟图是否连通无关



入度（In-degree）：
有向图（Directed Graph）中指向当前节点的点的个数（或指向当前节点的边的条数）
算法描述：
1. 统计每个点的入度

2. 将每个入度为 0 的点放入队列（Queue）中作为起始节点

3. 不断从队列中拿出一个点，去掉这个点的所有连边（指向其他点的边），其他点的相应的入度 - 1

4. 一旦发现新的入度为 0 的点，丢回队列中

  

  



（1）二叉树的BFS vs 图的BFS：
二叉树中进行 BFS 和图中进行 BFS 最大的区别就是二叉树中无需使用 HashSet来存储访问过的节点（丢进过 queue 里的节点）因为二叉树这种数据结构，上下层关系分明，没有环（circle），所以不可能出现一个节点的儿子的儿子是自己的情况。但是在图中，一个节点的邻居的邻居就可能是自己了。



**在入队列时加入set中，不是poll出来的时候加入set，会导致queue中节点重复**

![微信截图_20201018215346](img\微信截图_20201018215346.png)



模板：

![微信截图_20201018221501](img\微信截图_20201018221501.png)

（2）为什么 BFS 可以搜索到最短路？

因为BFS是按照层级进行搜索，所以搜到答案时，一定是最短的一条路径。

我们可以使用反证法进行证明：

我们假设当前搜索到的路径 Y 不是最短的，那就说明存在一条更短的路径 X（即 X < Y）。

令路径 X 中的所有点是 {x1,x2,...,xx}。

那么x1是起点，且为 BFS 的第一层，x2为第二层......xx为第x层，

此时的结果与BFS中第Y层初次遇到xx点产生矛盾。

因此不存在任何一条比Y短的路径能找到终点。

（3）图vs 矩阵

图 Graph
N个点，M条边
M最大是 O(N^2) 的级别
图上BFS时间复杂度 = O(N + M)
说是O(M)问题也不大，因为M一般都比N大
所以最坏情况可能是 O(N^2)
矩阵 Matrix
R行C列
R * C个点，R * C * 2 条边（每个点上下左右4条边，每条边被2个点共享）。
矩阵中BFS时间复杂度 = O(R * C)



# 十、DFS

碰到让你找所有方案的题，基本可以确定是 DFS
除了二叉树以外的 90% DFS 的题，要么是排列，要么是组合

dfs有点像先序遍历，而且是找出来所有方案

遍历法：通常会用到一个全局变量或者共享参数
分治法：通常会利用return value记录子问题结果，二叉树的分治法本质上也是做遍历，是**后序遍历**

时间复杂度通用计算公式
O(方案个数 * 构造每个方案的时间)
排列问题 = O(n! * n)
组合问题 = O(2^n * n)

1、遍历

**在递归时，返回值是void**

2、分治

**在递归时，返回值是其中一部分的结果**

![QQ截图20201007220844](img\QQ截图20201007220844.png)

3、Combination（组合），Subset（子集）

在非二叉树上的深度优先搜索（Depth-first Search）中，90%的问题，不是求组合（Combination）就是求排列（Permutation）。特别是组合类的深度优先搜索的问题特别的多。而排列组合类的搜索问题，本质上是一个“隐式图”的搜索问题。

一个问题如果没有明确的告诉你什么是点，什么是边，但是又需要你进行搜索的话，那就是一个隐式图搜索问题了。

对于“选代表”的方法来说，我们采取的办法是从若干个数字相同但顺序不同的小集合中拿出一个有序的集合作为代表，将剩下的无序集合舍弃。
那有没有一种数据结构，可以完成去重工作呢？答案自然是hash，所以我们可以对所有的集合进行哈希，每次将当前搜索到的集合subset放入结果集合subsets中的时候，只需将这个集合看做是key，如果对应的value不存在，就证明这个集合是个没出现过的新集合，这时再把新的集合放入subsets中即可。

在这段代码中，我们选择将subset从集合变成字符串，从而实现对集合的哈希。

```java
public class Solution {
    /**
     * @param nums: A set of numbers.
     * @return: A list of lists. All valid subsets.
     */
    public List<List<Integer>> subsetsWithDup(int[] nums) {
        List<List<Integer>> subsets = new ArrayList<>();
        HashMap<String, Boolean> visited = new HashMap<String, Boolean>();
        Arrays.sort(nums);
        dfs(nums, 0, new ArrayList<>(), subsets, visited);
        
        return subsets;
    }
    
    String getHash(List<Integer> subset) {
        String hashString = "";
        for (int i = 0;i < subset.size(); i++) {
            hashString += subset.get(i).toString();
            hashString += "_";
        }
        
        return hashString;
    }
    
    void dfs(int[] nums, 
             int startIndex, 
             List<Integer> subset,
             List<List<Integer>> subsets,
             HashMap<String, Boolean> visited) {
        String hashString = getHash(subset);
        
        if (visited.containsKey(hashString)) {
            return ;
        }
        
        visited.put(hashString, true);
        subsets.add(new ArrayList<Integer>(subset));
        for (int i = startIndex;i < nums.length; i++) {
            subset.add(nums[i]);
            dfs(nums, i + 1, subset, subsets, visited);
            subset.remove(subset.size() - 1);
        }
        
    }
    
}
```

4、排列

全排列问题是“排列式”深度优先搜索问题的鼻祖。

状压DP的主要思想就是利用一个二进制足够长的整数，使用相应的二进制位的状态（0或1）来记录某个点是否被走过

## 1、全排列 46

案例二：求出 N 个数组成的全排列

点：每个数为一个点
边：任意两两点之间都有连边，且为无向边
路径：= 排列 = 从任意点出发到任意点结束经过每个点一次且仅一次的路径

![微信截图_20201204100521](img\微信截图_20201204100521.png)

把数学上的全排列当成树，使用DFS，利用boolean[] visited数组标记元素。同时需要一个count来标记第一个数字的选择是否走到了数组的最后

![0bf18f9b86a2542d1f6aa8db6cc45475fce5aa329a07ca02a9357c2ead81eec1-image](img\0bf18f9b86a2542d1f6aa8db6cc45475fce5aa329a07ca02a9357c2ead81eec1-image.png)

## 2、组合 77

案例一：找出一个集合的所有子集

点：集合中的元素
边：元素与元素之间用 有向边连接，小的点指向大的点（为了避免选出 12 和 21 这种重复集合）
路径：= 子集 = 图中任意点出发到任意点结束的一条路径

![微信截图_20201204100247](img\微信截图_20201204100247.png)



用非递归（Non-recursion / Iteration）的方式实现全子集问题，有两种方式：

- 进制转换（binary）--布隆过滤器

- 宽度优先搜索（Breadth-first Search）

  （1）进制转换（binary）

```java
/**
     * @param S: A set of numbers.
     * @return: A list of lists. All valid subsets.
     */
    public List<List<Integer>> subsets(int[] nums) {
        List<List<Integer>> result = new ArrayList<List<Integer>>();
        int n = nums.length;
        Arrays.sort(nums);
        for (int i = 0; i < (1 << n); i++) {
            List<Integer> subset = new ArrayList<Integer>();
            for (int j = 0; j < n; j++) {
                if ((i & (1 << j)) != 0) {
                    subset.add(nums[j]);
                }
            }
            result.add(subset);
        }
        
        return result;
    }
```

（2）BFS

```
第一层: []
第二层: [1] [2] [3]
第三层: [1, 2] [1, 3], [2, 3]
第四层: [1, 2, 3]
```

```java
/*
     * @param nums: A set of numbers
     * @return: A list of lists
     */
    public List<List<Integer>> subsets(int[] nums) {
        // List vs ArrayList （google）
        List<List<Integer>> results = new LinkedList<>();
        
        if (nums == null) {
            return results; // 空列表
        }
        
        Arrays.sort(nums);
        
        // BFS
        Queue<List<Integer>> queue = new LinkedList<>();
        queue.offer(new ArrayList<Integer>());
        
        while (!queue.isEmpty()) {
            List<Integer> subset = queue.poll();
            results.add(subset);
            
            for (int i = 0; i < nums.length; i++) {
                if (subset.size() == 0 || subset.get(subset.size() - 1) < nums[i]) {
                    List<Integer> nextSubset = new ArrayList<Integer>(subset);
                    nextSubset.add(nums[i]);
                    queue.offer(nextSubset);
                }
            }
        }
        
        return results;
    }
```



# 十一、二分查找

**二分法的本质是：每次放弃一半的数据，左右边界逐渐逼近**

![微信截图_20201016124459](img\微信截图_20201016124459.png)



![微信截图_20201016194701](img\微信截图_20201016194701.png)

**linkedlist不能用递归写，容易Stack Overflow**



**求“值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。**

## 1、二分查找的变形

![4221d02a2e88e9053085920f13f9ce36](img\4221d02a2e88e9053085920f13f9ce36.jpg)

## 2、倍增思想

场景：
动态数组（ArrayList in Java)、网络重试

## 3、旋转数组

**旋转数组的本质：在切一刀后，依然是旋转数组，**如果旋转数组中有重复的值，那么就会退化到O(N)，因为如果再例子：[1,1,1,1,1….,1] 里藏着一个0最坏情况下需要把每个位置上的1都看一遍，才能找到最后一个有0的位置

![微信截图_20201117213542](img\微信截图_20201117213542.png)

## 2、通过 IP 地址来查找 IP 归属地的功能

假设我们有 12 万条这样的 IP 区间与归属地的对应关系，如何快速定位出一个 IP 地址的归属地呢？

```
[202.102.133.0, 202.102.133.255]  山东东营市 
[202.102.135.0, 202.102.136.255]  山东烟台 
[202.102.156.34, 202.102.157.255] 山东青岛 
[202.102.48.0, 202.102.48.255] 江苏宿迁 
[202.102.49.15, 202.102.51.251] 江苏泰州 
[202.102.56.0, 202.102.56.255] 江苏连云港
```

如果 IP 区间与归属地的对应关系不经常更新，我们可以先预处理这 12 万条数据，让其按照起始 IP （ip区间的左边）从小到大排序。如何来排序呢？我们知道，IP 地址可以转化为 32 位的整型数。所以，我们可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。

然后，这个问题就可以转化为我刚讲的第四种变形问题“在有序数组中，查找最后一个小于等于某个给定值的元素”了。

当我们要查询某个 IP 归属地时，我们可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，我们就取出对应的归属地显示；如果不在，就返回未查找到。

## 3、 [寻找两个正序数组的中位数](https://leetcode-cn.com/problems/median-of-two-sorted-arrays/)

给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。

请你找出这两个正序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。

你可以假设 nums1 和 nums2 不会同时为空。

（1）先解释下“割”
我们通过切一刀，能够把有序数组分成左右两个部分，切的那一刀就被称为割(Cut)，割(Cut)的左右会有两个元素，分别是左边最大值和右边最小值。

我们定义LMax= Max(LeftPart)，RMin = Min(RightPart)。

割可以割在两个数中间，也可以割在1个数上，如果割在一个数上，那么这个数即属于左边，也属于右边

奇数组: [2 3 5] 对应的中位数为3，假定割(Cut)在3上，我们可以把3分为2个： [2 （3/3) 5]

因此LMax=3, RMin=3

偶数组: [1 4 7 9] 对应的中位数为 (4 + 7) /2 = 5.5,假定割(Cut)在4和7之间： [1 （4/7) 9]

因此LMax=4, RMin=7

（2）LMax1<=RMin2，LMax2<=RMin1

![微信截图_20200826100053](img\微信截图_20200826100053.png)

那么如果 LMax1>RMin2，说明数组1的左边元素太大（多），我们把C1减小，C2=k-C1也就相应的增大。LMax2>RMin1同理，把C2减小，C1=k-C2也就相应的增大。

（3）虚拟加入‘#’

两个数组的最大问题是，它们合并后，m+n总数可能为奇, 也可能为偶，所以我们得想法让m+n总是为偶数

通过虚拟加入‘#’，我们让m转换成2m+1 ，n转换成2n+1, 两数之和就变成了2m+2n+2，恒为偶数。

注意是虚拟加，其实根本没这一步，通过下面的转换，我们可以保证虚拟加后每个元素跟原来的元素一一对应

![微信截图_20200826100515](img\微信截图_20200826100515.png)

这么虚拟加后，**每个位置可以通过/2得到原来元素的位置**：

比如 2，原来在`0`位，现在是1位，`1/2=0`

比如 3，原来在`1`位，现在是3位，`3/2=1`

而对于割(`Cut`)，如果割在`‘#’`上等于割在2个元素之间，割在数字上等于把数字划到2个部分，总是有以下成立：
$$
LMaxi = (Ci-1)/2 位置上的元素\\

RMini = Ci/2 位置上的元素
$$
割在3上，C = 3，LMax=a[(3-1)/2]=A[1]，RMin=a[3/2] =A[1]，刚好都是3的位置！

割在4/7之间‘#’，C = 4，LMax=A[(4-1)/2]=A[1]=4 ，RMin=A[4/2]=A[2]=7

（4）如果`C1`或`C2`已经到头了怎么办？

这种情况出现在：如果有个数组完全小于或大于中值。假定n<m, 可能有4种情况：

C1 = 0 —— 数组1整体都在右边了，所以都比中值大，中值在数组2中，简单的说就是数组1割后的左边是空了，所以我们可以假定LMax1 = INT_MIN

C1 =2n —— 数组1整体都在左边了，所以都比中值小，中值在数组2中 ，简单的说就是数组1割后的右边是空了，所以我们可以假定RMin1= INT_MAX，来保证LMax2<RMin1恒成立

C2 = 0 —— 数组2整体在右边了，所以都比中值大，中值在数组1中 ，简单的说就是数组2割后的左边是空了，所以我们可以假定LMax2 = INT_MIN

C2 = 2m —— 数组2整体在左边了，所以都比中值小，中值在数组1中, 简单的说就是数组2割后的右边是空了，为了让LMax1 < RMin2 恒成立，我们可以假定RMin2 = INT_MAX

转载至

作者：bian-bian-xiong
链接：https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/4-xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-shu/





# 十三、贪心

## 1、分糖果

我们有 m 个糖果和 n 个孩子。我们现在要把糖果分给这些孩子吃，但是糖果少，孩子多（m<n），所以糖果只能分配给一部分孩子。每个糖果的大小不等，这 m 个糖果的大小分别是 s1，s2，s3，……，sm。除此之外，每个孩子对糖果大小的需求也是不一样的，只有糖果的大小大于等于孩子的对糖果大小的需求的时候，孩子才得到满足。假设这 n 个孩子对糖果大小的需求分别是 g1，g2，g3，……，gn。我的问题是，如何分配糖果，能尽可能满足最多数量的孩子？

我们可以把这个问题抽象成，从 n 个孩子中，抽取一部分孩子分配糖果，让满足的孩子的个数（期望值）是最大的。这个问题的限制值就是糖果个数 m。我们现在来看看如何用贪心算法来解决。对于一个孩子来说，如果小的糖果可以满足，我们就没必要用更大的糖果，这样更大的就可以留给其他对糖果大小需求更大的孩子。另一方面，对糖果大小需求小的孩子更容易被满足，所以，我们可以从需求小的孩子开始分配糖果。因为满足一个需求大的孩子跟满足一个需求小的孩子，对我们期望值的贡献是一样的。我们每次从剩下的孩子中，找出对糖果大小需求最小的，然后发给他剩下的糖果中能满足他的最小的糖果，这样得到的分配方案，也就是满足的孩子个数最多的方案。

## 2、区间覆盖（任务调度、教师排课）

假设我们有 n 个区间，区间的起始端点和结束端点分别是[l1, r1]，[l2, r2]，[l3, r3]，……，[ln, rn]。我们从这 n 个区间中选出一部分区间，这部分区间满足两两不相交（端点相交的情况不算相交），最多能选出多少个区间呢？

我们假设这 n 个区间中最左端点是 lmin，最右端点是 rmax。这个问题就相当于，我们选择几个不相交的区间，从左到右将[lmin, rmax]覆盖上。我们按照起始端点从小到大的顺序对这 n 个区间排序。我们每次选择的时候，**左端点跟前面的已经覆盖的区间不重合的，右端点又尽量小的**，这样可以让剩下的未覆盖区间尽可能的大，就可以放置更多的区间。这实际上就是一种贪心的选择方法。



![ef2d0bd8284cb6e69294566a45b0e2b5](img\ef2d0bd8284cb6e69294566a45b0e2b5.jpg)

## 3、移除 k 个数字，让剩下的数字值最小

在一个非负整数 a 中，我们希望从中移除 k 个数字，让剩下的数字值最小，如何选择移除哪 k 个数字呢？

整数 a，由若干位数字组成，移除 k 个数字后的值最小。从高位开始移除：移除高位数字比它低位数字大的那个；K 次循环。

也可以用 Top K 排序，求出 K 个最大的数字，移除。

因为不管这个数字大的在哪一位上，都必须把他移除，否则，留下来的就不会是最小的

比如129,192,921，都必须把9移除

## 4、 n 个人总的等待时间最短

假设有 n 个人等待被服务，但是服务窗口只有一个，每个人需要被服务的时间长度是不同的，如何安排被服务的先后顺序，才能让这 n 个人总的等待时间最短？

每个人需要被服务的时间不一样，但所有人加起来总的被服务时间是固定的。

题意是求 n 个人总的等待时间，每个人在被服务之前，所经过的等待时间是不同的。

而当前被服务的人所需的服务时间，会累加到剩下的那些等待被服务人的等待时间上。

要使 n 个人总的等待时间最短，那么每次安排服务时间最短的那个人被服务：堆排序（小顶堆）。

## 5、121[买卖股票的最佳时机](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/)

# 十四、记忆化搜索（缓存）

记忆化搜索的缺陷
递归深度太深，导致 StackOverflow

1、什么是记忆化搜索
在函数返回前，记录函数的返回结果
在下一次以 同样参数访问函数时直接返回记录下的结果

2、记忆化搜索函数的三个特点
函数有返回值
函数返回结果之和输入参数相关，和其他全局状态无关
参数列表中传入哈希表或者其他用于记录计算结果的数据结构



**记忆化搜索时间复杂度=动态规划的时间复杂度=O(状态总数 * 计算每个状态的时间耗费)**



使用hashmap记录中间结果，避免了重复计算，不是避免没必要计算，可以将指数级别降低到多项式级别，本质是DP，它是dp的一种实现方式，**但是由于使用的是DFS，会有Stack Overflow的风险**

**而且这里的记忆化跟DFS中的visited还不一样，有点类似于更高层次的记忆**

通过将函数的计算结果保存下来，下次通过同样的参数访问时，直接返回保存的结果，所以这个函数必须有返回值

1、LeetCode120 三角形最小路径和

（1）dfs 遍历

![QQ截图20201028214312](img\QQ截图20201028214312.png)

（2）dfs 分治

![QQ截图20201028214629](img\QQ截图20201028214629.png)

（3）通过hashmap记忆化搜索

虽然每个节点都被访问了两次，但是第二次由于hashmap中已经保存了，所以是O(1)，没有进行计算

![QQ截图20201028214809](img\QQ截图20201028214809.png)



![微信图片_20201217194309](img\微信图片_20201217194309.jpg)

# 十五、DP

数字三角形用dp，二叉树用分治，因为分治的条件是两个 小问题不能有相关性，而dp正是由于有相关性，才能将结果保存，下次用的时候直接取出来，加速了过程

**dfs是从当下的点向后进行递归计算**
**dp不能是前边的依赖后边的，因为后边还没有计算，所以需要换一个角度，当前的点是从之前的点来的**
**所以dp需要初始化**

动态规划的时间复杂度
O(状态总数 * 每个状态的处理耗费)=O(状态总数 * 决策数)

## 1、三种适用动规的场景

• 求最值
• dp[] 的值的类型是最优值的类型
• dp[大问题] = max{dp[小问题1], dp[小问题2], ...}
• dp[大问题] = min{dp[小问题1], dp[小问题2], ...}
• 求方案数
• dp[] 的值的类型是方案数（整数）
• dp[大问题] = ∑(dp[小问题1], dp[小问题2], ...)
• ∑=sum
• 求可行性
• dp[] 的值是 true / false
• dp[大问题] = dp[小问题1] or dp[小问题2] or ...
• 代码通常用 for 小问题 if dp[小问题] == true then break 的形式实现

2、三种不适用 三种不适用 DP 的场景

求出所有的具体方案
• http://www.lintcode.com/problem/palindrome-partitioning/
• 只求出一个具体方案还是可以用 DP 来做的（下节课）
• 该判断标准成功率 99%
• 输入数据是无序的
• http://www.lintcode.com/problem/longest-consecutive-sequence/
• 背包类动态规划不适用此判断条件
• 除去背包问题后，该判断标准成功率 60-70%，有一些题可以先排序之后按序处理
• 暴力算法的复杂度已经是多项式级别
• http://www.lintcode.com/problem/largest-rectangle-in-histogram/
• 动态规划擅长与优化指数级别复杂度(2^n,n!)到多项式级别复杂度(n^2,n^3)
• 不擅长优化n^3到n^2
• 该判断标准成功率 80%
• 则  极不可能 使用动态规划求解



![微信截图_20201225192421](img\微信截图_20201225192421.png)



![微信截图_20201225192511](img\微信截图_20201225192511.png)



## **2、空间优化技巧——滚动数组**

如果**状态依赖关系只在相邻的几层之间**，则可以使用滚动数组进行优化，滚动数组可以让空间复杂度降维

**要想滚动，必须下标是递增或者递减，不能前后都依赖**

**滚动数组滚动的是第一重循环的变量，也就是说，即使滚动的是j，j也是先循环**
而不是第二重甚至第三重
滚动数组也只能滚一个维度
不能两个维度一起滚动

判断能不能用滚动数组，就是看它是不是只与本行和前一行有关，具体写的时候可以用old和now，或者用模来写。但是不太推荐用模，因为模在计算机中是一个比较慢的操作。

```
坐标型动态规划使用滚动数组
数字三角形的状态转移方程为
dp[i][j] = min(dp[i - 1][j], dp[i - 1][j - 1]) + A[i][j]
滚动数组优化之后为
dp[i % 2][j] = min(dp[(i - 1) % 2][j], dp[(i - 1) % 2][j - 1]) + A[i][j]
```

```
fibonacci数列的滚动数组优化
dp[i] = dp[i - 1] + dp[i - 2]
滚动数组优化后
dp[i % 3] = dp[(i - 1) % 3] + dp[(i - 2) % 3]

骑士最短路径的滚动数组优化
https://www.lintcode.com/problem/knight-shortest-path-ii/
dp[i][j] = min{dp[i - 1][j - 2], dp[i + 1][j - 2], dp[i - 2][j - 1], dp[i + 2][j - 1]}
滚动数组优化后为？
dp[i][j] = min{dp[i - 1][(j - 2) % 3], dp[i + 1][(j - 2) % 3], dp[i - 2][(j - 1) % 3], dp[i + 2][(j - 1) % 3]}

01背包的滚动数组优化
dp[i][j] 代表前 i 个物品取出若干装满大小 j 的背包最多装多少
dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - A[i]] + A[i])
优化之后
dp[i % 2][j] = max(dp[(i - 1) % 2][j], dp[(i - 1) % 2][j - A[i]] + A[i])
```



## 1、最长公共子串

![微信截图_20200827200923](img\微信截图_20200827200923.png)

## 2、最长公共子序列

![微信截图_20200827191205](img\微信截图_20200827191205.png)

## 3、矩阵的不同路径

62题

![微信图片_20200827215011](img\微信图片_20200827215011.jpg)



## 4、购物车薅羊毛

购物车中有 n 个（n>100）想买的商品，她希望从里面选几个，在凑够满减条件的前提下，让选出来的商品价格总和最大程度地接近满减条件（200 元），这样就可以极大限度地“薅羊毛”。



## 5、如何实现搜索引擎中的拼写纠错功能？

两个字符串的相似度，编辑距离

根据所包含的编辑操作种类的不同，编辑距离有多种不同的计算方式，比较著名的有**莱文斯坦距离**（Levenshtein distance）和**最长公共子序列长度**（Longest common substring length）。其中，莱文斯坦距离允许增加、删除、替换字符这三个编辑操作，最长公共子串长度只允许增加、删除字符这两个编辑操作。

莱文斯坦距离的大小，表示两个字符串差异的大小；而最长公共子串的大小，表示两个字符串相似程度的大小。

![f0e72008ce8451609abed7e368ac420f](img\f0e72008ce8451609abed7e368ac420f.jpg)



当用户在搜索框内，输入一个拼写错误的单词时，我们就拿这个单词跟词库中的单词一一进行比较，计算编辑距离，将编辑距离最小的单词，作为纠正之后的单词，提示给用户。这就是拼写纠错最基本的原理。

不过，真正用于商用的搜索引擎，拼写纠错功能显然不会就这么简单。一方面，单纯利用编辑距离来纠错，效果并不一定好；另一方面，词库中的数据量可能很大，搜索引擎每天要支持海量的搜索，所以对纠错的性能要求很高。

**针对纠错效果不好的问题，我们有很多种优化思路，我这里介绍几种。**

- 我们并不仅仅取出编辑距离最小的那个单词，而是取出编辑距离最小的 TOP 10，然后根据其他参数，决策选择哪个单词作为拼写纠错单词。比如使用搜索热门程度来决定哪个单词作为拼写纠错单词。
- 我们还可以用多种编辑距离计算方法，比如今天讲到的两种，然后分别编辑距离最小的 TOP 10，然后求交集，用交集的结果，再继续优化处理。
- 我们还可以通过统计用户的搜索日志，得到最常被拼错的单词列表，以及对应的拼写正确的单词。搜索引擎在拼写纠错的时候，首先在这个最常被拼错单词列表中查找。如果一旦找到，直接返回对应的正确的单词。这样纠错的效果非常好。
- 我们还有更加高级一点的做法，引入个性化因素。针对每个用户，维护这个用户特有的搜索喜好，也就是常用的搜索关键词。当用户输入错误的单词的时候，我们首先在这个用户常用的搜索关键词中，计算编辑距离，查找编辑距离最小的单词。

**针对纠错性能方面，我们也有相应的优化方式。我讲两种分治的优化思路。**

- 如果纠错功能的 TPS 不高，我们可以部署多台机器，每台机器运行一个独立的纠错功能。当有一个纠错请求的时候，我们通过负载均衡，分配到其中一台机器，来计算编辑距离，得到纠错单词。
- 如果纠错系统的响应时间太长，也就是，每个纠错请求处理时间过长，我们可以将纠错的词库，分割到很多台机器。当有一个纠错请求的时候，我们就将这个拼写错误的单词，同时发送到这多台机器，让多台机器并行处理，分别得到编辑距离最小的单词，然后再比对合并，最终决定出一个最优的纠错单词。

## 6、322. [零钱兑换](https://leetcode-cn.com/problems/coin-change/)

题目：给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。

本题目是dp，有点像完全背包，所以是由最优子结构转移来的，假设F(i)代表组成金额i的最少硬币：
$$
F(i)=min[F(i-ci)]+1
$$
ci代表加入第i个硬币后满足金额i，而ci不能是最大面值，因为需要遍历整个coins组，可能选了最大值之后，反而得不到解，所以F(i-ci)加上ci这个硬币得到了F(i)

7、区间型DP

子数组、子序列、子串都可能是在暗示区间DP，DP很难处理具体方案，但是可以很简单的处理答案总数。

是否可以使用滚动数组和DP类型无关，和DP的转移方程有直接关联，如果DP状态的依赖关系较简单：如 i 依赖 i-1 就可以用，如果 i 依赖 0,1,2,...,(i-1) 就没必要使用。

8、划分型DP

划分型动态规划本质上是一种前缀型动态规划，一般情况下，它的状态都定义为诸如“前i个字符”，“前i个数字”等。

9、接龙型动态规划

接龙型动态规划是一种典型的一维动态规划，往往是根据题目接龙要求，求解最长的一条"龙"的长度。
最长上升子序列（LIS，longest increasing subsequence）问题，

# 十六、分治

## 1、二维平面上有 n 个点，如何快速计算出两个距离最近的点对？

（1）暴力破解O(n^2)

（2）分治法

https://www.geeksforgeeks.org/closest-pair-of-points-using-divide-and-conquer-algorithm/?ref=lbp

1. 将输入的数组按照x坐标排序
2. 二分法，分为左右两部分
3. 在左右两个部分中递归计算最小的距离，分别得到dl和dr，求得d=Min(dl,dr)
4. 接着求一个点在左边，一个在右边的距离，为此建立以中点为轴，x-d和x+d的宽度的范围，
5. 在这个范围中以y坐标进行排序O(nlogn)，<font color=red>**这里排序可能并不需要**</font>
6. 然后计算每个点与其他点之间的距离，可以证明，在这个范围内，最多只有8个点，所以O(8*n)
7. 对比d和S中计算得到的距离，得到最小距离
8. 整体的O(n (Logn)^2)

![closepair](img\closepair.png)

![微信截图_20200908141241](img\微信截图_20200908141241.png)

（3）改进的分治法，时间复杂度O(nLogn) 

https://www.geeksforgeeks.org/closest-pair-of-points-onlogn-implementation/?ref=lbp

1. 在（2）中预处理时，就把原始的点的数组分别按照x坐标和y坐标做排序处理
2. 每次在分的时候，就把对应的y也按照mid分开，那么在最后计算2d范围内的点的坐标时，也就是按照y排序好的，复杂度会降下来



## 2、有两个 n\*n 的矩阵 A，B，如何快速求解两个矩阵的乘积 C=A\*B？

3、Kth Smallest Element in BST

二叉树经常被修改，如何优化 kthSmallest 这个操作？

在 TreeNode 中增加一个 counter，代表整个树的节点个数
也可以用一个 HashMap<TreeNode, Integer> 来存储某个节点为代表的子树的节点个数
在增删查改的过程中记录不断更新受影响节点的 counter
在 kthSmallest 的实现中用类似 Quick Select 的算法去找到 kth smallest element
时间复杂度为 O(h)，h 为树的高度。

# 十七、位图与布隆过滤器

（1）假设我们有 1 亿个整数，数据范围是从 1 到 10 亿，如何快速并且省内存地给这 1 亿个数据从小到大排序？

传统的做法：1亿个整数，存储需要400M空间，排序时间复杂度最优 N×log(N)

使用位图算法：数字范围是1到10亿，用位图存储125M就够了，然后将1亿个数字依次添加到位图中，然后再将位图按下标从小到大输出值为1的下标，排序就完成了，时间复杂度为 N。对于重复的 可以再维护一个小的散列表 记录出现次数超过1次的数据以及对应的个数





